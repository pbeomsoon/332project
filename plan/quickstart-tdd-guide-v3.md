# QuickStart: TDD Implementation Guide (v3 - Final)

**ëª©ì **: ëª¨ë“  ì„¤ê³„ ë¬¸ì„œì™€ ì™„ë²½íˆ ì •ë ¬ëœ TDD êµ¬í˜„ ê°€ì´ë“œ
**ì‘ì„±ì¼**: 2025-11-02
**ë²„ì „**: 3.0 (ìµœì¢… - ëª¨ë“  ë¬¸ì„œì™€ ì¼ì¹˜)

---

## ğŸš¨ Critical Changes from v2

### 1. **Phase ì˜ì¡´ì„± ê¸°ë°˜ TDD ìˆœì„œ ì¬ì •ë¦½**

```diff
- Cycle 3: BinaryRecordWriter (Phase 4ìš©)
- Cycle 4: AsciiRecordReader
- Cycle 5: AsciiRecordWriter
- Cycle 6: InputFormatDetector

+ Cycle 2: RecordReader trait (NEW)
+ Cycle 3: BinaryRecordReader refactoring
+ Cycle 4: AsciiRecordReader (Phase 1-2 í•„ìˆ˜)
+ Cycle 5: InputFormatDetector (Phase 1-2 í•„ìˆ˜)
```

### 2. **í•µì‹¬ ì´ìœ **

**plan_ver3.md Line 536-539 (Phase 1 Sampling)**:
```scala
for (file <- getAllInputFiles(inputDirs)) {
  val format = InputFormatDetector.detectFormat(file)  // â­ í•„ìˆ˜!
  val reader = RecordReader.create(format)
}
```

- Phase 1(Sampling)ê³¼ Phase 2(Sort)ì—ì„œ InputFormatDetectorê°€ **í•„ìˆ˜**
- WriterëŠ” Phase 4(Merge)ì—ì„œë§Œ í•„ìš” â†’ ë‚˜ì¤‘ì— êµ¬í˜„ ê°€ëŠ¥

---

## ğŸ“‹ TDD Cycles - Complete Roadmap

### Phase 0: Foundation âœ…

#### Cycle 1: Record (ì™„ë£Œ)
```scala
// âœ… ì´ë¯¸ êµ¬í˜„ë¨
case class Record(key: Array[Byte], value: Array[Byte]) extends Ordered[Record]
```

#### Cycle 2: RecordReader Abstraction (NEW - 10ë¶„)

**í…ŒìŠ¤íŠ¸ (RED)**:
```scala
class RecordReaderSpec extends AnyFlatSpec with Matchers {
  "DataFormat" should "have Binary and Ascii types" in {
    val binary = DataFormat.Binary
    val ascii = DataFormat.Ascii
    binary should not be ascii
  }

  "RecordReader trait" should "be implemented by BinaryRecordReader" in {
    val reader: RecordReader = new BinaryRecordReader(testFile)
    reader shouldBe a[RecordReader]
    reader.getFile shouldBe testFile
  }

  "RecordReader.create" should "create correct reader based on format" in {
    val reader = RecordReader.create(testFile, DataFormat.Binary)
    reader shouldBe a[BinaryRecordReader]
  }
}
```

**êµ¬í˜„ (GREEN)**:
```scala
// RecordReader.scala
sealed trait DataFormat
object DataFormat {
  case object Binary extends DataFormat
  case object Ascii extends DataFormat
}

trait RecordReader {
  def readRecord(): Option[Record]
  def close(): Unit
  def getFile: File
}

object RecordReader {
  def create(file: File, format: DataFormat): RecordReader = format match {
    case DataFormat.Binary => new BinaryRecordReader(file)
    case DataFormat.Ascii =>
      throw new NotImplementedError("AsciiRecordReader not yet implemented")
  }
}
```

---

### Phase 1-2: Input Processing (Critical Path) ğŸ”¥

#### Cycle 3: BinaryRecordReader Refactoring (5ë¶„)

**ë¦¬íŒ©í† ë§**:
```scala
// BinaryRecordReader.scala
class BinaryRecordReader(file: File) extends RecordReader {  // â† Add extends
  // ... ê¸°ì¡´ êµ¬í˜„ ìœ ì§€ ...

  override def getFile: File = file  // â† Add this method
}
```

#### Cycle 4: AsciiRecordReader (40ë¶„)

**ASCII í˜•ì‹ (gensort -a)**:
```
ì´ 201 characters + newline:
48656C6C6F576F726C64 576F726C6448656C6C6F...
â””â”€â”€ 20 hex chars â”€â”€â”˜ â””â”€â”€ 180 hex chars â”€â”€â”€â”€â”˜
    (10-byte key)        (90-byte value)
```

**í…ŒìŠ¤íŠ¸ (RED)**:
```scala
class AsciiRecordReaderSpec extends AnyFlatSpec with Matchers {

  def toHex(bytes: Array[Byte]): String =
    bytes.map("%02X".format(_)).mkString

  def createAsciiFile(records: Seq[Record]): Path = {
    val tempFile = Files.createTempFile("test", ".txt")
    val writer = new PrintWriter(tempFile.toFile)
    records.foreach { r =>
      writer.println(s"${toHex(r.key)} ${toHex(r.value)}")
    }
    writer.close()
    tempFile
  }

  "AsciiRecordReader" should "read gensort ASCII format" in {
    // Given
    val records = Seq(
      Record(Array[Byte](1,2,3,4,5,6,7,8,9,10), Array.fill[Byte](90)(0))
    )
    val file = createAsciiFile(records)

    // When
    val reader = new AsciiRecordReader(file.toFile)
    val read = reader.readRecord()

    // Then
    read shouldBe defined
    read.get shouldBe records(0)
  }

  it should "handle case-insensitive hex" in {
    // 0xAB == 0xab
  }

  it should "reject invalid line length" in {
    // Must be exactly 201 characters
  }

  it should "reject invalid hex" in {
    // 'G' is not hex
  }

  it should "handle EOF" in {
    // Return None at end
  }

  it should "handle empty file" in {
    // Return None immediately
  }
}
```

**êµ¬í˜„ (GREEN)**:
```scala
class AsciiRecordReader(file: File) extends RecordReader {
  private val reader = new BufferedReader(new FileReader(file), 1024 * 1024)

  override def readRecord(): Option[Record] = {
    val line = reader.readLine()
    if (line == null) return None

    // Validate length
    if (line.length != 201) {
      throw new IllegalArgumentException(s"Invalid length: ${line.length}")
    }

    // Validate space
    if (line.charAt(20) != ' ') {
      throw new IllegalArgumentException("Missing space at position 20")
    }

    // Parse hex
    val keyHex = line.substring(0, 20)
    val valueHex = line.substring(21, 201)

    val key = hexToBytes(keyHex)
    val value = hexToBytes(valueHex)

    Some(Record(key, value))
  }

  private def hexToBytes(hex: String): Array[Byte] = {
    hex.grouped(2).map(Integer.parseInt(_, 16).toByte).toArray
  }

  override def close(): Unit = reader.close()
  override def getFile: File = file
}
```

#### Cycle 5: InputFormatDetector (30ë¶„)

**ìë™ ê°ì§€ ì•Œê³ ë¦¬ì¦˜**:
```
1. Read first 1000 bytes
2. Count ASCII printable (0x20-0x7E, \n, \r)
3. Ratio > 0.9 â†’ ASCII, else â†’ Binary
```

**í…ŒìŠ¤íŠ¸ (RED)**:
```scala
class InputFormatDetectorSpec extends AnyFlatSpec with Matchers {

  "InputFormatDetector" should "detect binary format" in {
    val file = createBinaryFile(Array.fill[Byte](1000)(0xFF))
    InputFormatDetector.detectFormat(file) shouldBe DataFormat.Binary
  }

  it should "detect ASCII format" in {
    val file = createAsciiFile(10) // 10 gensort records
    InputFormatDetector.detectFormat(file) shouldBe DataFormat.Ascii
  }

  it should "handle empty file" in {
    // Default to Binary
  }

  it should "use majority rule for mixed content" in {
    // 90% ASCII â†’ ASCII
    // 80% ASCII â†’ Binary
  }

  it should "handle small files" in {
    // < 1000 bytes
  }
}
```

**êµ¬í˜„ (GREEN)**:
```scala
object InputFormatDetector extends LazyLogging {

  def detectFormat(file: File): DataFormat = {
    val buffer = new Array[Byte](1000)
    val input = new FileInputStream(file)

    try {
      val bytesRead = input.read(buffer)

      if (bytesRead <= 0) {
        logger.warn(s"Empty file: ${file.getName}")
        return DataFormat.Binary
      }

      val asciiCount = buffer.take(bytesRead).count { b =>
        (b >= 32 && b <= 126) || b == '\n' || b == '\r'
      }

      val asciiRatio = asciiCount.toDouble / bytesRead

      if (asciiRatio > 0.9) {
        logger.info(s"Detected ASCII: ${file.getName}")
        DataFormat.Ascii
      } else {
        logger.info(s"Detected Binary: ${file.getName}")
        DataFormat.Binary
      }
    } finally {
      input.close()
    }
  }
}
```

**RecordReader Factory ì™„ì„±**:
```scala
object RecordReader {
  def create(file: File, format: DataFormat): RecordReader = format match {
    case DataFormat.Binary => new BinaryRecordReader(file)
    case DataFormat.Ascii => new AsciiRecordReader(file)  // âœ… Now works!
  }

  def create(file: File): RecordReader = {
    val format = InputFormatDetector.detectFormat(file)  // âœ… Auto-detect!
    create(file, format)
  }
}
```

---

### Phase 1-2: Integration Test (20ë¶„)

```scala
class Phase1IntegrationSpec extends AnyFlatSpec with Matchers {

  "Phase 1 Sampling" should "work with mixed input" in {
    // Given: Binary + ASCII files
    val binaryFile = createBinaryFile(1000)
    val asciiFile = createAsciiFile(1000)

    // When: Sample with auto-detection
    val samples = Seq(binaryFile, asciiFile).flatMap { file =>
      val reader = RecordReader.create(file)  // Auto-detect!

      val samples = mutable.ArrayBuffer[Record]()
      var count = 0

      Iterator.continually(reader.readRecord())
        .takeWhile(_.isDefined)
        .map(_.get)
        .foreach { record =>
          if (count % 10 == 0) samples += record  // 10% sample
          count += 1
        }

      reader.close()
      samples
    }

    // Then
    samples should have length 200  // 10% of 2000
  }

  "Phase 2 Sort" should "handle auto-detected formats" in {
    // Given
    val mixedFiles = createMixedInputDirectory()

    // When
    val sorter = new ExternalSorter()
    mixedFiles.foreach { file =>
      val reader = RecordReader.create(file)  // Auto-detect!
      // ... sorting logic ...
    }

    // Then: All sorted correctly
  }
}
```

---

### Phase 2-3: Core Algorithms (Week 3 Day 3-4)

#### Cycle 6: Sampler
```scala
class Sampler {
  def extractSamples(files: Seq[File], sampleRate: Double): Seq[Record] = {
    files.flatMap { file =>
      val reader = RecordReader.create(file)  // Uses auto-detection!
      // ... sampling logic ...
    }
  }
}
```

#### Cycle 7: ExternalSorter
```scala
class ExternalSorter {
  def sortChunk(file: File): File = {
    val reader = RecordReader.create(file)  // Auto-detection!
    // ... sorting logic ...
  }
}
```

#### Cycle 8: Partitioner
```scala
class Partitioner(boundaries: Array[Array[Byte]]) {
  def getPartition(record: Record): Int = {
    // Binary search in boundaries
  }
}
```

#### Cycle 9: ShuffleMap
```scala
object ShuffleMap {
  def create(numPartitions: Int, numWorkers: Int): Map[Int, Int] = {
    (0 until numPartitions).map { p =>
      p -> (p / (numPartitions / numWorkers))
    }.toMap
  }
}
```

---

### Phase 4: Output (Week 3 Day 5)

#### Cycle 10: BinaryRecordWriter
```scala
class BinaryRecordWriter(file: File) extends RecordWriter {
  private val output = new BufferedOutputStream(
    new FileOutputStream(file), 1024 * 1024
  )

  def writeRecord(record: Record): Unit = {
    output.write(record.toBytes)
  }

  def close(): Unit = output.close()
}
```

#### Cycle 11: AsciiRecordWriter
```scala
class AsciiRecordWriter(file: File) extends RecordWriter {
  private val writer = new BufferedWriter(new FileWriter(file))

  def writeRecord(record: Record): Unit = {
    val keyHex = toHex(record.key)
    val valueHex = toHex(record.value)
    writer.write(s"$keyHex $valueHex\n")
  }

  def close(): Unit = writer.close()
}
```

---

## ğŸ¯ Milestone ê²€ì¦

### Milestone 1: Core Components (Day 1-2)
```bash
# Run tests
sbt test

# Expected output:
[info] RecordSpec:
[info] - Record should store 10-byte key and 90-byte value
[info] - Record should compare by key only
[info] RecordReaderSpec:
[info] - DataFormat should have Binary and Ascii types
[info] - RecordReader.create should create correct reader
[info] BinaryRecordReaderSpec:
[info] - should read binary records
[info] AsciiRecordReaderSpec:
[info] - should read ASCII records
[info] InputFormatDetectorSpec:
[info] - should detect formats correctly
```

### Milestone 2: Phase 1-2 Integration (Day 2)
```bash
# Test with gensort data
gensort -b0 10000 test_binary.dat
gensort -a 10000 test_ascii.dat

# Run integration test
sbt "testOnly *IntegrationSpec"

# Verify auto-detection
sbt "runMain distsort.TestAutoDetection test_binary.dat test_ascii.dat"
```

---

## ğŸ“Š ì§„í–‰ ì¶”ì 

### Week 3 Timeline

#### Day 1 (ì™„ë£Œ)
- âœ… Cycle 1: Record
- âœ… Cycle 2: BinaryRecordReader (partial)

#### Day 2 (í˜„ì¬)
- [ ] Cycle 2: RecordReader trait
- [ ] Cycle 3: BinaryRecordReader refactoring
- [ ] Cycle 4: AsciiRecordReader
- [ ] Cycle 5: InputFormatDetector
- [ ] Integration tests

#### Day 3
- [ ] Cycle 6: Sampler
- [ ] Cycle 7: ExternalSorter
- [ ] Cycle 8: Partitioner

#### Day 4
- [ ] Cycle 9: ShuffleMap
- [ ] Cycle 10: BinaryRecordWriter
- [ ] Cycle 11: AsciiRecordWriter

#### Day 5
- [ ] FileLayout
- [ ] End-to-end test
- [ ] Performance optimization

---

## âœ… ì¦‰ì‹œ ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Step 1: RecordReader trait (10ë¶„)
```bash
# 1. Create file
touch src/main/scala/distsort/core/RecordReader.scala

# 2. Write test
touch src/test/scala/distsort/core/RecordReaderSpec.scala

# 3. Run test (RED)
sbt "testOnly distsort.core.RecordReaderSpec"

# 4. Implement (GREEN)
# 5. Run test again
sbt "testOnly distsort.core.RecordReaderSpec"
```

### Step 2: Refactor BinaryRecordReader (5ë¶„)
```bash
# 1. Add "extends RecordReader"
# 2. Add getFile method
# 3. Run existing tests (should still pass)
sbt "testOnly distsort.core.BinaryRecordReaderSpec"
```

### Step 3: AsciiRecordReader (40ë¶„)
```bash
# 1. Create test
touch src/test/scala/distsort/core/AsciiRecordReaderSpec.scala

# 2. Run test (RED)
sbt "testOnly distsort.core.AsciiRecordReaderSpec"

# 3. Create implementation
touch src/main/scala/distsort/core/AsciiRecordReader.scala

# 4. Run test (GREEN)
sbt "testOnly distsort.core.AsciiRecordReaderSpec"
```

### Step 4: InputFormatDetector (30ë¶„)
```bash
# Similar process...
```

### Step 5: Integration Test (20ë¶„)
```bash
# Create test file
touch src/test/scala/distsort/integration/Phase1IntegrationSpec.scala

# Run all tests
sbt test

# Check coverage
sbt clean coverage test coverageReport
```

---

## ğŸ”¥ í•µì‹¬ ì°¨ì´ì  (v2 â†’ v3)

### 1. **InputFormatDetector ìµœìš°ì„ **
- Phase 1-2ì—ì„œ ì¦‰ì‹œ í•„ìš”
- ëª¨ë“  íŒŒì¼ ì½ê¸°ì˜ ê¸°ë°˜

### 2. **RecordReader ì¶”ìƒí™” í•„ìˆ˜**
- Factory pattern êµ¬í˜„
- Auto-detection ì§€ì›

### 3. **WriterëŠ” ë‚˜ì¤‘ì—**
- Phase 4ì—ì„œë§Œ í•„ìš”
- Inputì´ ìš°ì„ 

### 4. **Integration Test ì¡°ê¸° ì‹œì‘**
- Phase 1-2 ê²€ì¦
- Mixed input í…ŒìŠ¤íŠ¸

---

## ğŸ“š ì°¸ì¡° ë¬¸ì„œ

### í•„ìˆ˜ í™•ì¸
1. `plan_ver3.md` Section 4.1.2, 12
2. `docs/0-implementation-decisions.md` Section 6.1
3. `docs/7-testing-strategy.md`
4. `docs/9-tdd-plan-alignment-final.md`

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### Technical
- [ ] Auto-detection works (no --ascii flag)
- [ ] gensort -a format supported
- [ ] Mixed input handled correctly
- [ ] Phase 1-2 integration tests pass

### Performance
- [ ] < 10ms per file detection
- [ ] < 2s for 1000 ASCII records
- [ ] < 1s for 1000 binary records

### Quality
- [ ] 90%+ test coverage
- [ ] All edge cases handled
- [ ] TDD cycle strictly followed

---

**Version**: 3.0 (Final)
**Date**: 2025-11-02
**Status**: âœ… **READY - Aligned with all documents**
**Next**: Start with RecordReader trait (Cycle 2)