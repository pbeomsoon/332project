# Distributed Sorting System - ìƒì„¸ ì„¤ê³„ ë¬¸ì„œ (v3)

**ì‘ì„±ì¼**: 2025-10-24
**ë²„ì „**: 3.0 (íŒŒí‹°ì…˜ ì „ëµ ëª…í™•í™”)
**í”„ë¡œì íŠ¸**: Fault-Tolerant Distributed Key/Value Sorting System

---

## ğŸ“‹ Version 3 ì£¼ìš” ë³€ê²½ì‚¬í•­

ì´ ë¬¸ì„œëŠ” v2ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **íŒŒí‹°ì…˜ ì „ëµì„ ëª…í™•íˆ êµ¬ë¶„**í•˜ê³  **shuffleMap ë¡œì§ì„ ì¶”ê°€**í•œ ë²„ì „ì…ë‹ˆë‹¤.

### ğŸ”¥ v3ì˜ í•µì‹¬ ê°œì„ 
1. **Simple vs Advanced íŒŒí‹°ì…˜ ì „ëµ ëª…í™•í•œ êµ¬ë¶„**
2. **shuffleMap ìƒì„± ë° ì‚¬ìš© ë¡œì§ ì¶”ê°€**
3. **ë‘ ê°€ì§€ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ì œê³µ**
4. **íŒŒí‹°ì…˜ í• ë‹¹ ê³µì‹ ëª…ì‹œ**
5. **Master ì¶œë ¥ì˜ ì˜ë¯¸ ìƒì„¸ ì„¤ëª…**
6. **Shuffle ì•Œê³ ë¦¬ì¦˜ ì™„ì „íˆ ì¬ì‘ì„±**

### ğŸ“Š v2 ëŒ€ë¹„ ë³€ê²½ì‚¬í•­
- âœ… íŒŒí‹°ì…˜ ì „ëµ A (Simple: Nâ†’N) vs B (Advanced: Nâ†’M) êµ¬ë¶„
- âœ… shuffleMap ê³„ì‚° ë¡œì§ ì¶”ê°€
- âœ… Workerê°€ ì—¬ëŸ¬ partition íŒŒì¼ ìƒì„±í•˜ëŠ” ê²½ìš° ëª…í™•í™”
- âœ… íŒŒí‹°ì…˜ ë²ˆí˜¸ê°€ ì—°ì†ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŒì„ ì„¤ëª…
- âœ… í˜¼ë€ì„ ì•¼ê¸°í•˜ë˜ ë‹¤ì´ì–´ê·¸ë¨ ë‘ ê°€ì§€ ë²„ì „ìœ¼ë¡œ ë¶„ë¦¬

---

## ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#2-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜) â­ ëŒ€í­ ìˆ˜ì •
3. [ë°ì´í„° êµ¬ì¡° ë° í¬ë§·](#3-ë°ì´í„°-êµ¬ì¡°-ë°-í¬ë§·) â­ ìˆ˜ì •
4. [í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ìƒì„¸](#4-í•µì‹¬-ì•Œê³ ë¦¬ì¦˜-ìƒì„¸) â­ ìˆ˜ì •
5. [ë„¤íŠ¸ì›Œí¬ í†µì‹  ì„¤ê³„](#5-ë„¤íŠ¸ì›Œí¬-í†µì‹ -ì„¤ê³„)
6. [ì¥ì•  í—ˆìš©ì„± ë©”ì»¤ë‹ˆì¦˜](#6-ì¥ì• -í—ˆìš©ì„±-ë©”ì»¤ë‹ˆì¦˜)
7. [ë©€í‹°ìŠ¤ë ˆë“œ ë° ë³‘ë ¬ ì²˜ë¦¬](#7-ë©€í‹°ìŠ¤ë ˆë“œ-ë°-ë³‘ë ¬-ì²˜ë¦¬)
8. [êµ¬í˜„ ì„¸ë¶€ì‚¬í•­](#8-êµ¬í˜„-ì„¸ë¶€ì‚¬í•­)
9. [ì„±ëŠ¥ ìµœì í™” ì „ëµ](#9-ì„±ëŠ¥-ìµœì í™”-ì „ëµ)
10. [í…ŒìŠ¤íŠ¸ ì „ëµ](#10-í…ŒìŠ¤íŠ¸-ì „ëµ)
11. [ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤ ìƒì„¸](#11-ëª…ë ¹í–‰-ì¸í„°í˜ì´ìŠ¤-ìƒì„¸)
12. [ì…ë ¥ í˜•ì‹ ì²˜ë¦¬](#12-ì…ë ¥-í˜•ì‹-ì²˜ë¦¬)
13. [ê°œë°œ ë§ˆì¼ìŠ¤í†¤](#13-ê°œë°œ-ë§ˆì¼ìŠ¤í†¤) â­ ìˆ˜ì •
14. [ì°¸ê³  ìë£Œ](#14-ì°¸ê³ -ìë£Œ)
15. [ì˜ˆìƒ ì´ìŠˆ ë° í•´ê²°ì±…](#15-ì˜ˆìƒ-ì´ìŠˆ-ë°-í•´ê²°ì±…)
16. [ê²°ë¡ ](#16-ê²°ë¡ )

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ëª©í‘œ
ì—¬ëŸ¬ ë¨¸ì‹ ì— ë¶„ì‚° ì €ì¥ëœ ëŒ€ìš©ëŸ‰ key/value ë ˆì½”ë“œë¥¼ ì •ë ¬í•˜ëŠ” ì¥ì•  í—ˆìš©ì„± ë¶„ì‚° ì‹œìŠ¤í…œ êµ¬í˜„

### 1.2 í•µì‹¬ ìš”êµ¬ì‚¬í•­
- **ì…ë ¥**: ì—¬ëŸ¬ Worker ë…¸ë“œì— ë¶„ì‚°ëœ 32MB ë¸”ë¡ ë‹¨ìœ„ì˜ ë¯¸ì •ë ¬ ë°ì´í„°
- **ì¶œë ¥**: ì „ì—­ì ìœ¼ë¡œ ì •ë ¬ëœ ë°ì´í„° (ê° Workerì— ì—°ì†ëœ íŒŒí‹°ì…˜ ì €ì¥)
- **ì¥ì•  í—ˆìš©**: Worker í”„ë¡œì„¸ìŠ¤ crash í›„ ì¬ì‹œì‘ ì‹œ ì˜¬ë°”ë¥¸ ê²°ê³¼ ìƒì„±
- **í™•ì¥ì„±**: ë©€í‹°ì½”ì–´ í™œìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
- **í˜•ì‹ ì§€ì›**: ASCII ë° Binary ì…ë ¥ ëª¨ë‘ ì§€ì›

### 1.3 ì œì•½ì‚¬í•­
- ì…ë ¥ ë””ë ‰í† ë¦¬ ìˆ˜ì • ê¸ˆì§€ (ì½ê¸° ì „ìš©)
- ì¶œë ¥ ë””ë ‰í† ë¦¬ì—ëŠ” ìµœì¢… ê²°ê³¼ë§Œ ì €ì¥
- í¬íŠ¸ í•˜ë“œì½”ë”© ê¸ˆì§€
- Akka ì‚¬ìš© ê¸ˆì§€
- ASCII/Binary í˜•ì‹ì€ **ìë™ ê°ì§€** (ëª…ë ¹í–‰ ì˜µì…˜ ì—†ì´)

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ â­ ëŒ€í­ ìˆ˜ì •

### 2.1 íŒŒí‹°ì…˜ ì „ëµ

**PDF ìš”êµ¬ì‚¬í•­ (Algorithm Phase 1):**
> `numPartitions - íŒŒí‹°ì…˜ ê°œìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ ì›Œì»¤ ìˆ˜ì™€ ë™ì¼ ë˜ëŠ” ë°°ìˆ˜)`

**PDF ìš”êµ¬ì‚¬í•­ (Output ì‚¬ì–‘):**
> `íŒŒì¼ ìˆœì„œ: ê° ì›Œì»¤ ë‚´ì—ì„œ partition.n, partition.n+1, ... í˜•ì‹`

ë³¸ ì‹œìŠ¤í…œì€ **ë‘ ê°€ì§€ íŒŒí‹°ì…˜ ì „ëµ**ì„ ì§€ì›í•©ë‹ˆë‹¤.

---

#### **Strategy A: Simple (N Workers â†’ N Partitions)** â­ ê¸°ë³¸ êµ¬í˜„ (Milestone 1-3)

**ê°œë…:**
- Worker ìˆ˜ì™€ íŒŒí‹°ì…˜ ìˆ˜ê°€ ë™ì¼ (1:1 ë§¤í•‘)
- ê° WorkerëŠ” **ì •í™•íˆ í•˜ë‚˜ì˜ íŒŒí‹°ì…˜**ë§Œ ë‹´ë‹¹
- Worker Index = Partition ID

**íŠ¹ì§•:**
- âœ… êµ¬í˜„ ë‹¨ìˆœ, ì´í•´ ìš©ì´
- âœ… ë””ë²„ê¹… ì‰¬ì›€
- âœ… Milestone 1-3ì—ì„œ ê²€ì¦í•˜ê¸° ì¢‹ìŒ
- âš ï¸ ë¡œë“œ ë¶ˆê· í˜• ë°œìƒ ê°€ëŠ¥
- âš ï¸ ë©€í‹°ì½”ì–´ í™œìš© ì œí•œì 

**ì£¼ì˜:** Strategy AëŠ” ë‹¨ìˆœ êµ¬í˜„ìš©ì´ë©°, ìµœì¢… ì‹œìŠ¤í…œì€ Strategy Bë¥¼ ì‚¬ìš©í•´ì•¼ í•¨

**ì˜ˆì‹œ: 3 Workers, ê° 50GB ì…ë ¥**

```
Phase 2: Sort & Partition
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker 0 â”‚  â”‚ Worker 1 â”‚  â”‚ Worker 2 â”‚
â”‚  50GB    â”‚  â”‚  50GB    â”‚  â”‚  50GB    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚sort          â”‚sort          â”‚sort
     â†“              â†“              â†“
   ì •ë ¬ë¨         ì •ë ¬ë¨         ì •ë ¬ë¨
     â”‚              â”‚              â”‚
     â†“partition(3)  â†“partition(3)  â†“partition(3)
     â”‚              â”‚              â”‚
  â”Œâ”€â”€â”´â”€â”€â”¬â”€â”€â”    â”Œâ”€â”€â”´â”€â”€â”¬â”€â”€â”    â”Œâ”€â”€â”´â”€â”€â”¬â”€â”€â”
  P0  P1  P2    P0  P1  P2    P0  P1  P2
  17G 16G 17G   17G 16G 17G   17G 16G 17G

Phase 3: Shuffle (shuffleMap: {0â†’0, 1â†’1, 2â†’2})
  ëª¨ë“  Workerì˜ P0 â†’ Worker 0
  ëª¨ë“  Workerì˜ P1 â†’ Worker 1
  ëª¨ë“  Workerì˜ P2 â†’ Worker 2

Phase 4: Merge
  Worker 0: 3ê°œ P0 ì¡°ê° merge â†’ partition.0 (50GB)
  Worker 1: 3ê°œ P1 ì¡°ê° merge â†’ partition.1 (50GB)
  Worker 2: 3ê°œ P2 ì¡°ê° merge â†’ partition.2 (50GB)

ìµœì¢… ì¶œë ¥:
  /worker0/output/partition.0  â† ì „ì²´ P0, ê°€ì¥ ì‘ì€ key
  /worker1/output/partition.1  â† ì „ì²´ P1, ì¤‘ê°„ key
  /worker2/output/partition.2  â† ì „ì²´ P2, ê°€ì¥ í° key

Master ì¶œë ¥:
  worker0:30000, worker1:30001, worker2:30002

ì½ê¸° ìˆœì„œ:
  partition.0 â†’ partition.1 â†’ partition.2 = ì „ì—­ ì •ë ¬ë¨
```

---

#### **Strategy B: Advanced (N Workers â†’ M Partitions, M > N)** âœ… PDF ìš”êµ¬ì‚¬í•­ (í•„ìˆ˜)

**PDF ê·¼ê±°:**
- Algorithm Phase 1: "numPartitions - íŒŒí‹°ì…˜ ê°œìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ ì›Œì»¤ ìˆ˜ì™€ ë™ì¼ **ë˜ëŠ” ë°°ìˆ˜**)"
- Output ì‚¬ì–‘: "ê° ì›Œì»¤ ë‚´ì—ì„œ partition.n, partition.n+1, ... í˜•ì‹" â†’ ì—¬ëŸ¬ íŒŒì¼ ê°€ëŠ¥

**ê°œë…:**
- íŒŒí‹°ì…˜ ìˆ˜ > Worker ìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ M = 3N)
- ê° WorkerëŠ” **ì—¬ëŸ¬ íŒŒí‹°ì…˜**ì„ ë‹´ë‹¹
- Partition iëŠ” Worker (i / partitionsPerWorker)ê°€ ë‹´ë‹¹

**íŠ¹ì§•:**
- âœ… ë¡œë“œ ë°¸ëŸ°ì‹± ê°œì„ 
- âœ… ë©€í‹°ì½”ì–´ í™œìš© ì¦ê°€
- âœ… íŒŒí‹°ì…˜ í¬ê¸° ë¶ˆê· í˜• ì™„í™”
- âœ… PDF ìš”êµ¬ì‚¬í•­ ì¶©ì¡±
- âš ï¸ êµ¬í˜„ ë³µì¡ë„ ì¦ê°€
- âš ï¸ Shuffle í†µì‹ ëŸ‰ ë™ì¼ (íŒŒí‹°ì…˜ ìˆ˜ì™€ ë¬´ê´€)

**íŒŒí‹°ì…˜ í• ë‹¹ ê³µì‹ (Range-based):**
```scala
def assignWorker(partitionID: Int, numWorkers: Int, numPartitions: Int): Int = {
  val partitionsPerWorker = numPartitions / numWorkers
  val workerID = partitionID / partitionsPerWorker
  if (workerID >= numWorkers) numWorkers - 1 else workerID
}

// ì˜ˆì‹œ: numPartitions=9, numWorkers=3
//   partitionsPerWorker = 9/3 = 3
//   partition 0: 0/3 = 0 â†’ Worker 0
//   partition 1: 1/3 = 0 â†’ Worker 0
//   partition 2: 2/3 = 0 â†’ Worker 0
//   partition 3: 3/3 = 1 â†’ Worker 1
//   partition 4: 4/3 = 1 â†’ Worker 1
//   partition 5: 5/3 = 1 â†’ Worker 1
//   partition 6: 6/3 = 2 â†’ Worker 2
//   partition 7: 7/3 = 2 â†’ Worker 2
//   partition 8: 8/3 = 2 â†’ Worker 2
//
// ê²°ê³¼: Worker 0 = [0,1,2], Worker 1 = [3,4,5], Worker 2 = [6,7,8]
//       ê° WorkerëŠ” ì—°ì†ëœ partition ë²ˆí˜¸ ë‹´ë‹¹
```

**ì˜ˆì‹œ: 3 Workers, 9 Partitions**

```
Phase 2: Sort & Partition
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker 0 â”‚  â”‚ Worker 1 â”‚  â”‚ Worker 2 â”‚
â”‚  50GB    â”‚  â”‚  50GB    â”‚  â”‚  50GB    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚sort          â”‚sort          â”‚sort
     â†“              â†“              â†“
   ì •ë ¬ë¨         ì •ë ¬ë¨         ì •ë ¬ë¨
     â”‚              â”‚              â”‚
     â†“partition(9)  â†“partition(9)  â†“partition(9)
     â”‚              â”‚              â”‚
  P0..P8         P0..P8         P0..P8
  ê° ~5.5GB

Phase 3: Shuffle (shuffleMap: {0â†’0, 1â†’0, 2â†’0, 3â†’1, 4â†’1, 5â†’1, 6â†’2, 7â†’2, 8â†’2})
  P0, P1, P2 â†’ Worker 0
  P3, P4, P5 â†’ Worker 1
  P6, P7, P8 â†’ Worker 2

Phase 4: Merge
  Worker 0:
    - 3ê°œ P0 ì¡°ê° merge â†’ partition.0
    - 3ê°œ P1 ì¡°ê° merge â†’ partition.1
    - 3ê°œ P2 ì¡°ê° merge â†’ partition.2

  Worker 1:
    - 3ê°œ P3 ì¡°ê° merge â†’ partition.3
    - 3ê°œ P4 ì¡°ê° merge â†’ partition.4
    - 3ê°œ P5 ì¡°ê° merge â†’ partition.5

  Worker 2:
    - 3ê°œ P6 ì¡°ê° merge â†’ partition.6
    - 3ê°œ P7 ì¡°ê° merge â†’ partition.7
    - 3ê°œ P8 ì¡°ê° merge â†’ partition.8

ìµœì¢… ì¶œë ¥:
  /worker0/output/
    â”œâ”€â”€ partition.0  â† ê°€ì¥ ì‘ì€ key
    â”œâ”€â”€ partition.1
    â””â”€â”€ partition.2

  /worker1/output/
    â”œâ”€â”€ partition.3
    â”œâ”€â”€ partition.4
    â””â”€â”€ partition.5

  /worker2/output/
    â”œâ”€â”€ partition.6
    â”œâ”€â”€ partition.7
    â””â”€â”€ partition.8  â† ê°€ì¥ í° key

Master ì¶œë ¥:
  141.223.91.80:30040
  worker0, worker1, worker2

ì½ê¸° ìˆœì„œ:
  partition.0 â†’ partition.1 â†’ partition.2 â†’
  partition.3 â†’ partition.4 â†’ partition.5 â†’
  partition.6 â†’ partition.7 â†’ partition.8
  = ì „ì—­ ì •ë ¬ë¨
```

---

### 2.2 ì „ì²´ êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨

#### **Strategy A (Simple) ë‹¤ì´ì–´ê·¸ë¨**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Master Node                        â”‚
â”‚  - Worker ë“±ë¡ ê´€ë¦¬                                      â”‚
â”‚  - ìƒ˜í”Œ ìˆ˜ì§‘ ë° íŒŒí‹°ì…˜ ê²½ê³„ ê³„ì‚° (Nê°œ)                    â”‚
â”‚  - shuffleMap ìƒì„±: {0â†’0, 1â†’1, 2â†’2, ...}               â”‚
â”‚  - ìµœì¢… Worker ìˆœì„œ ì¶œë ¥                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ Worker 0 â”‚   â”‚ Worker 1 â”‚  â”‚ Worker 2 â”‚
â”‚(index=0) â”‚   â”‚(index=1) â”‚  â”‚(index=2) â”‚
â”‚          â”‚   â”‚          â”‚  â”‚          â”‚
â”‚ Input:   â”‚   â”‚ Input:   â”‚  â”‚ Input:   â”‚
â”‚ 50GB     â”‚   â”‚ 50GB     â”‚  â”‚ 50GB     â”‚
â”‚          â”‚   â”‚          â”‚  â”‚          â”‚
â”‚ Output:  â”‚   â”‚ Output:  â”‚  â”‚ Output:  â”‚
â”‚partition.0   â”‚partition.1   â”‚partition.2
â”‚(1 file)  â”‚   â”‚(1 file)  â”‚  â”‚(1 file)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        Worker-to-Worker Shuffle
        (ê° WorkerëŠ” í•˜ë‚˜ì˜ íŒŒí‹°ì…˜ë§Œ ë‹´ë‹¹)
```

#### **Strategy B (Advanced) ë‹¤ì´ì–´ê·¸ë¨**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Master Node                        â”‚
â”‚  - Worker ë“±ë¡ ê´€ë¦¬                                      â”‚
â”‚  - ìƒ˜í”Œ ìˆ˜ì§‘ ë° íŒŒí‹°ì…˜ ê²½ê³„ ê³„ì‚° (Mê°œ)                    â”‚
â”‚  - shuffleMap ìƒì„±: {0â†’0, 1â†’1, 2â†’2, 3â†’0, 4â†’1, ...}    â”‚
â”‚  - ìµœì¢… Worker ìˆœì„œ ì¶œë ¥                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ Worker 0 â”‚   â”‚ Worker 1 â”‚  â”‚ Worker 2 â”‚
â”‚(index=0) â”‚   â”‚(index=1) â”‚  â”‚(index=2) â”‚
â”‚          â”‚   â”‚          â”‚  â”‚          â”‚
â”‚ Input:   â”‚   â”‚ Input:   â”‚  â”‚ Input:   â”‚
â”‚ 50GB     â”‚   â”‚ 50GB     â”‚  â”‚ 50GB     â”‚
â”‚          â”‚   â”‚          â”‚  â”‚          â”‚
â”‚ Output:  â”‚   â”‚ Output:  â”‚  â”‚ Output:  â”‚
â”‚P0,P1,P2  â”‚   â”‚P3,P4,P5  â”‚  â”‚P6,P7,P8  â”‚
â”‚          â”‚   â”‚          â”‚  â”‚          â”‚
â”‚partition.0   â”‚partition.3   â”‚partition.6
â”‚partition.1   â”‚partition.4   â”‚partition.7
â”‚partition.2   â”‚partition.5   â”‚partition.8
â”‚(3 files) â”‚   â”‚(3 files) â”‚  â”‚(3 files) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        Worker-to-Worker Shuffle
        (ê° WorkerëŠ” ì—¬ëŸ¬ íŒŒí‹°ì…˜ ë‹´ë‹¹)

ìµœì¢… ì½ê¸° ìˆœì„œ:
  partition.0 â†’ partition.1 â†’ partition.2 â†’
  partition.3 â†’ partition.4 â†’ partition.5 â†’
  partition.6 â†’ partition.7 â†’ partition.8
```

---

### 2.3 ì‹¤í–‰ íë¦„

```
Phase 0: ì´ˆê¸°í™”
  - Master ì‹œì‘, Workerë“¤ ë“±ë¡ ëŒ€ê¸°
  - ê° Worker ì‹œì‘, Masterì— ì—°ê²° ë° ë“±ë¡
  - Masterê°€ Workerì— index í• ë‹¹
  - ë””ìŠ¤í¬ ê³µê°„ ê²€ì¦

Phase 1: Sampling (ìƒ˜í”Œë§)
  - ê° Workerê°€ ì…ë ¥ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ
  - ë™ì  ìƒ˜í”Œë§ ë¹„ìœ¨ ê³„ì‚°
  - Masterì—ê²Œ ìƒ˜í”Œ ì „ì†¡
  - Masterê°€ ì „ì²´ ìƒ˜í”Œ ì •ë ¬ ë° íŒŒí‹°ì…˜ ê²½ê³„ ê³„ì‚° (Nê°œ or Mê°œ)
  - shuffleMap ìƒì„± ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸

Phase 2: Sort & Partition (ì •ë ¬ ë° íŒŒí‹°ì…”ë‹)
  - ê° Workerê°€ ì…ë ¥ ë¸”ë¡ ì½ê¸° (ASCII/Binary ìë™ ì²˜ë¦¬)
  - ë©”ëª¨ë¦¬ ë‚´ ì •ë ¬
  - íŒŒí‹°ì…˜ ê²½ê³„ì— ë”°ë¼ Nê°œ ë˜ëŠ” Mê°œ íŒŒí‹°ì…˜ìœ¼ë¡œ ë¶„í• 
  - íŒŒí‹°ì…˜ë³„ ì„ì‹œ íŒŒì¼ ìƒì„±

Phase 3: Shuffle (ë°ì´í„° ì¬ë¶„ë°°)
  - shuffleMapì— ë”°ë¼ íŒŒí‹°ì…˜ ì „ì†¡
  - Worker (i mod N)ì´ íŒŒí‹°ì…˜ ië¥¼ ë°›ìŒ
  - Worker ê°„ ë„¤íŠ¸ì›Œí¬ í†µì‹  (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
  - íƒ€ì„ì•„ì›ƒ ë° ë°±ì˜¤í”„ ì²˜ë¦¬

Phase 4: Merge (ë³‘í•©)
  - ê° Workerê°€ ë°›ì€ íŒŒí‹°ì…˜ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ K-way merge
  - Strategy A: 1ê°œ partition íŒŒì¼ ìƒì„± (ì˜ˆ: Worker 0 â†’ partition.0)
  - Strategy B: ì—¬ëŸ¬ ê°œ partition íŒŒì¼ ìƒì„± (ì˜ˆ: Worker 0 â†’ partition.0, partition.1, partition.2)
  - Atomic write ë³´ì¥

Phase 5: ì™„ë£Œ
  - ê° Workerê°€ Masterì—ê²Œ ì™„ë£Œ ë³´ê³ 
  - Masterê°€ ì „ì²´ ì‘ì—… ì™„ë£Œ í™•ì¸
  - Masterê°€ ì •ë ¬ëœ Worker ì£¼ì†Œ ì¶œë ¥ (stdout)
  - ì„ì‹œ íŒŒì¼ ì •ë¦¬
```

---

## 3. ë°ì´í„° êµ¬ì¡° ë° í¬ë§· â­ ìˆ˜ì •

### 3.1 ë ˆì½”ë“œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Key (10B)    â”‚ Value (90B)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  0            10                                          100
```

**íŠ¹ì§•:**
- ê³ ì • ê¸¸ì´: 100 ë°”ì´íŠ¸
- Keyë§Œ ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
- ValueëŠ” ì •ë ¬ê³¼ ë¬´ê´€í•˜ê²Œ Keyì™€ í•¨ê»˜ ì´ë™

### 3.2 Key ë¹„êµ ê·œì¹™

```scala
def compareKeys(keyA: Array[Byte], keyB: Array[Byte]): Int = {
  for (i <- 0 until 10) {
    if (keyA(i) != keyB(i)) {
      // unsigned byte ë¹„êµ
      return (keyA(i) & 0xFF).compareTo(keyB(i) & 0xFF)
    }
  }
  0 // ë™ì¼
}
```

### 3.3 ì…ë ¥ ë°ì´í„° êµ¬ì¡°

```
Input Directories:
/data1/input/
  â”œâ”€â”€ block_0001  (32MB)
  â”œâ”€â”€ block_0002  (32MB)
  â””â”€â”€ ...

/data2/input/
  â”œâ”€â”€ block_0001  (32MB)
  â””â”€â”€ ...

ì´ ì…ë ¥: 50GB x N workers
```

### 3.4 ì¶œë ¥ ë°ì´í„° êµ¬ì¡° â­ ëŒ€í­ ìˆ˜ì •

#### **Strategy A (Simple): ê° Worker 1ê°œ íŒŒì¼**

```
Worker 0 (index=0):
  /output/partition.0  (ì „ì²´ P0 ë°ì´í„°)

Worker 1 (index=1):
  /output/partition.1  (ì „ì²´ P1 ë°ì´í„°)

Worker 2 (index=2):
  /output/partition.2  (ì „ì²´ P2 ë°ì´í„°)

íŒŒì¼ ëª…ëª… ê·œì¹™:
  - partition.{worker_index}
  - ê° WorkerëŠ” ì •í™•íˆ í•˜ë‚˜ì˜ íŒŒì¼ ìƒì„±
  - íŒŒì¼ ë²ˆí˜¸ = Worker Index = Partition ID
```

#### **Strategy B (Advanced): ê° Worker ì—¬ëŸ¬ íŒŒì¼**

```
Worker 0 (index=0):
  /output/
    â”œâ”€â”€ partition.0  (ì „ì²´ P0 ë°ì´í„°)
    â”œâ”€â”€ partition.1  (ì „ì²´ P1 ë°ì´í„°)
    â””â”€â”€ partition.2  (ì „ì²´ P2 ë°ì´í„°)

Worker 1 (index=1):
  /output/
    â”œâ”€â”€ partition.3  (ì „ì²´ P3 ë°ì´í„°)
    â”œâ”€â”€ partition.4  (ì „ì²´ P4 ë°ì´í„°)
    â””â”€â”€ partition.5  (ì „ì²´ P5 ë°ì´í„°)

Worker 2 (index=2):
  /output/
    â”œâ”€â”€ partition.6  (ì „ì²´ P6 ë°ì´í„°)
    â”œâ”€â”€ partition.7  (ì „ì²´ P7 ë°ì´í„°)
    â””â”€â”€ partition.8  (ì „ì²´ P8 ë°ì´í„°)

íŒŒì¼ ëª…ëª… ê·œì¹™:
  - partition.{partition_id}
  - ì—°ì†ëœ partition ë²ˆí˜¸ ë‹´ë‹¹ (range-based í• ë‹¹)
  - Worker iëŠ” íŒŒí‹°ì…˜ ë²”ìœ„ [i*M/N, (i+1)*M/N) ë‹´ë‹¹
    (ì˜ˆ: Worker 0 â†’ [0,3), Worker 1 â†’ [3,6), Worker 2 â†’ [6,9))
```

### 3.5 ì¤‘ê°„ ë°ì´í„° êµ¬ì¡°

```
Temporary Directory (ì‘ì—… ì¤‘):
${TEMP_DIR}/sort_work_${WORKER_ID}/
  â”œâ”€â”€ samples/
  â”‚   â””â”€â”€ sample.dat  (ë™ì  í¬ê¸°)
  â”‚
  â”œâ”€â”€ sorted_chunks/
  â”‚   â”œâ”€â”€ chunk_0000.sorted  (100MB)
  â”‚   â”œâ”€â”€ chunk_0001.sorted  (100MB)
  â”‚   â””â”€â”€ ...
  â”‚
  â”œâ”€â”€ partitions/
  â”‚   â”œâ”€â”€ partition_0/
  â”‚   â”‚   â”œâ”€â”€ from_chunk_0000.dat
  â”‚   â”‚   â”œâ”€â”€ from_chunk_0001.dat
  â”‚   â”‚   â””â”€â”€ ...
  â”‚   â”œâ”€â”€ partition_1/
  â”‚   â”‚   â””â”€â”€ ...
  â”‚   â””â”€â”€ ...
  â”‚
  â””â”€â”€ received/
      â”œâ”€â”€ partition_0_from_worker_1.dat
      â”œâ”€â”€ partition_0_from_worker_2.dat
      â””â”€â”€ ...

TEMP_DIR ì§€ì •:
  - --temp í”Œë˜ê·¸ë¡œ ì§€ì • (ê¸°ë³¸ê°’: /tmp)
  - ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ ì‚¬ì „ í™•ì¸ í•„ìš”
  - ì‘ì—… ì™„ë£Œ í›„ ìë™ ì‚­ì œ
```

---

## 4. í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ ìƒì„¸ â­ ëŒ€í­ ìˆ˜ì •

### 4.1 Phase 1: Sampling Algorithm

#### 4.1.1 ë™ì  ìƒ˜í”Œë§ ë¹„ìœ¨ ê³„ì‚°

```scala
def calculateSampleRate(totalInputSize: Long, numWorkers: Int): Double = {
  // Workerë‹¹ ëª©í‘œ ìƒ˜í”Œ ê°œìˆ˜ (10,000ê°œ key)
  val targetSamplesPerWorker = 10000
  val totalTargetSamples = targetSamplesPerWorker * numWorkers

  // ì „ì²´ ë ˆì½”ë“œ ìˆ˜ ì¶”ì •
  val estimatedTotalRecords = totalInputSize / 100

  // ìƒ˜í”Œë§ ë¹„ìœ¨ ê³„ì‚°
  val calculatedRate = totalTargetSamples.toDouble / estimatedTotalRecords

  // ìµœì†Œ/ìµœëŒ€ ì œí•œ
  val minRate = 0.0001  // 0.01%
  val maxRate = 0.01    // 1%

  math.max(minRate, math.min(maxRate, calculatedRate))
}
```

#### 4.1.2 ìƒ˜í”Œ ì¶”ì¶œ (ê° Worker) â­ ìˆ˜ì •

```scala
def extractSample(inputDirs: List[String],
                  totalInputSize: Long,
                  numWorkers: Int): Array[Array[Byte]] = {

  val sampleRate = calculateSampleRate(totalInputSize, numWorkers)
  val random = new Random(42)  // ì¬í˜„ ê°€ëŠ¥ì„±ì„ ìœ„í•œ ê³ ì • seed
  val samples = mutable.ArrayBuffer[Array[Byte]]()

  for (file <- getAllInputFiles(inputDirs)) {
    // â­ ê° íŒŒì¼ë§ˆë‹¤ í˜•ì‹ ìë™ ê°ì§€
    val format = InputFormatDetector.detectFormat(file)
    val reader = RecordReader.create(format)

    val input = new BufferedInputStream(new FileInputStream(file))

    var record = reader.readRecord(input)
    while (record.isDefined) {
      if (random.nextDouble() < sampleRate) {
        val key = record.get.take(10)
        samples += key
      }
      record = reader.readRecord(input)
    }
    input.close()
  }

  samples.toArray
}
```

#### 4.1.3 íŒŒí‹°ì…˜ ê²½ê³„ ê³„ì‚° (Master)

```scala
def calculatePartitionBoundaries(
    allSamples: Array[Array[Byte]],
    numPartitions: Int): Array[Array[Byte]] = {

  // 1. ëª¨ë“  ìƒ˜í”Œ ì •ë ¬
  val sortedSamples = allSamples.sortWith(compareKeys(_, _) < 0)

  // 2. ê· ë“± ë¶„í• ì„ ìœ„í•œ ê²½ê³„ ì„ íƒ
  val boundaries = new Array[Array[Byte]](numPartitions - 1)
  val step = sortedSamples.length / numPartitions

  for (i <- 0 until numPartitions - 1) {
    boundaries(i) = sortedSamples((i + 1) * step)
  }

  boundaries
}
```

#### 4.1.4 shuffleMap ìƒì„± (Master) â­ NEW

```scala
def createShuffleMap(numWorkers: Int, numPartitions: Int): Map[Int, Int] = {
  val shuffleMap = mutable.Map[Int, Int]()
  val partitionsPerWorker = numPartitions / numWorkers

  for (partitionID <- 0 until numPartitions) {
    // íŒŒí‹°ì…˜ IDë¥¼ Worker IDë¡œ ë§¤í•‘
    val workerID = partitionID / partitionsPerWorker
    val finalWorkerID = if (workerID >= numWorkers) numWorkers - 1 else workerID
    shuffleMap(partitionID) = finalWorkerID
  }

  shuffleMap.toMap
}

// ì˜ˆì‹œ
// Strategy A: createShuffleMap(3, 3)
//   â†’ {0â†’0, 1â†’1, 2â†’2}
//
// Strategy B: createShuffleMap(3, 9)
//   â†’ {0â†’0, 1â†’1, 2â†’2, 3â†’0, 4â†’1, 5â†’2, 6â†’0, 7â†’1, 8â†’2}
```

### 4.2 Phase 2: Sort & Partition Algorithm

#### 4.2.1 ì²­í¬ ë‹¨ìœ„ ì •ë ¬ â­ ìˆ˜ì •

```scala
def sortChunk(inputFile: File,
              chunkSize: Int = 100 * 1024 * 1024): File = {
  // â­ íŒŒì¼ í˜•ì‹ ìë™ ê°ì§€
  val format = InputFormatDetector.detectFormat(inputFile)
  val reader = RecordReader.create(format)

  val records = new Array[Array[Byte]](chunkSize / 100)
  val input = new BufferedInputStream(new FileInputStream(inputFile))

  var count = 0
  var record = reader.readRecord(input)

  while (count < records.length && record.isDefined) {
    records(count) = record.get
    count += 1
    record = reader.readRecord(input)
  }
  input.close()

  // ì •ë ¬ (key ê¸°ì¤€)
  val sortedRecords = records.take(count).sortWith { (a, b) =>
    compareKeys(a.take(10), b.take(10)) < 0
  }

  // ì„ì‹œ íŒŒì¼ ì €ì¥
  val outputFile = createTempFile("chunk_", ".sorted")
  val output = new BufferedOutputStream(new FileOutputStream(outputFile))
  sortedRecords.foreach(output.write)
  output.close()

  outputFile
}
```

#### 4.2.2 íŒŒí‹°ì…”ë‹

```scala
def partitionSortedChunk(
    sortedChunk: File,
    boundaries: Array[Array[Byte]],
    numPartitions: Int,
    outputDir: File): Unit = {

  // numPartitionsê°œì˜ íŒŒí‹°ì…˜ íŒŒì¼ ìƒì„±
  val partitionWriters = (0 until numPartitions).map { i =>
    new BufferedOutputStream(
      new FileOutputStream(new File(outputDir, s"partition_$i.dat"), true),
      1024 * 1024  // 1MB ë²„í¼
    )
  }.toArray

  val input = new BufferedInputStream(new FileInputStream(sortedChunk))
  val record = new Array[Byte](100)

  while (input.read(record) == 100) {
    val key = record.take(10)
    val partitionId = findPartitionBinarySearch(key, boundaries)
    partitionWriters(partitionId).write(record)
  }

  input.close()
  partitionWriters.foreach(_.close())
}

def findPartitionBinarySearch(key: Array[Byte],
                               boundaries: Array[Array[Byte]]): Int = {
  var left = 0
  var right = boundaries.length

  while (left < right) {
    val mid = (left + right) / 2
    if (compareKeys(key, boundaries(mid)) < 0) {
      right = mid
    } else {
      left = mid + 1
    }
  }
  left
}
```

### 4.3 Phase 3: Shuffle Algorithm â­ ì™„ì „ ì¬ì‘ì„±

#### 4.3.1 Worker Shuffle ì‹¤í–‰

```scala
def shufflePartitions(
    localPartitions: Map[Int, File],      // ì´ Workerê°€ ìƒì„±í•œ íŒŒí‹°ì…˜ë“¤
    shuffleMap: Map[Int, Int],             // partitionID â†’ workerID
    myWorkerIndex: Int,
    allWorkers: List[WorkerInfo]): Map[Int, List[File]] = {

  val receivedPartitions = mutable.Map[Int, mutable.ListBuffer[File]]()

  // 1. ìì‹ ì´ ë‹´ë‹¹í•  íŒŒí‹°ì…˜ ëª©ë¡ íŒŒì•…
  val myPartitionIDs = shuffleMap.filter(_._2 == myWorkerIndex).keys.toSet

  logger.info(s"Worker $myWorkerIndex is responsible for partitions: ${myPartitionIDs.mkString(", ")}")

  // 2. ë¡œì»¬ íŒŒí‹°ì…˜ ì²˜ë¦¬
  for ((partitionID, file) <- localPartitions) {
    val targetWorkerID = shuffleMap(partitionID)

    if (targetWorkerID == myWorkerIndex) {
      // ìì‹ ì´ ë‹´ë‹¹í•˜ëŠ” íŒŒí‹°ì…˜ â†’ ë¡œì»¬ì— ìœ ì§€
      receivedPartitions.getOrElseUpdate(partitionID, mutable.ListBuffer()) += file
      logger.debug(s"Partition $partitionID kept locally")
    } else {
      // ë‹¤ë¥¸ Workerë¡œ ì „ì†¡
      sendPartitionWithRetry(file, partitionID, allWorkers(targetWorkerID))
      logger.debug(s"Partition $partitionID sent to Worker $targetWorkerID")
    }
  }

  // 3. ë‹¤ë¥¸ Workerë¡œë¶€í„° ìˆ˜ì‹ 
  for (partitionID <- myPartitionIDs) {
    for (otherWorker <- allWorkers if otherWorker.index != myWorkerIndex) {
      val receivedFile = receivePartition(partitionID, otherWorker)
      receivedPartitions.getOrElseUpdate(partitionID, mutable.ListBuffer()) += receivedFile
      logger.debug(s"Received partition $partitionID from Worker ${otherWorker.index}")
    }
  }

  // 4. Map[PartitionID -> List[File]] ë°˜í™˜
  receivedPartitions.map { case (k, v) => (k, v.toList) }.toMap
}
```

#### 4.3.2 ì†¡ì‹  (Sender) with Retry

```scala
def sendPartitionWithRetry(
    partitionFile: File,
    partitionId: Int,
    targetWorker: WorkerInfo,
    maxRetries: Int = 3): Unit = {

  var attempt = 0
  var success = false

  while (attempt < maxRetries && !success) {
    try {
      sendPartition(partitionFile, partitionId, targetWorker)
      success = true
    } catch {
      case e: StatusRuntimeException if isRetryable(e) =>
        attempt += 1
        val backoffMs = math.pow(2, attempt).toLong * 1000
        logger.warn(s"Send failed (attempt $attempt/$maxRetries), " +
                   s"retrying in ${backoffMs}ms: ${e.getMessage}")
        Thread.sleep(backoffMs)

      case e: Exception =>
        logger.error(s"Non-retryable send error: ${e.getMessage}")
        throw e
    }
  }

  if (!success) {
    throw new IOException(s"Failed to send partition $partitionId after $maxRetries attempts")
  }
}

def sendPartition(
    partitionFile: File,
    partitionId: Int,
    targetWorker: WorkerInfo): Unit = {

  val channel = createGrpcChannelWithRetry(targetWorker.host, targetWorker.port)
  val stub = WorkerServiceGrpc.newStub(channel)

  val responseObserver = new StreamObserver[ShuffleAck] {
    override def onNext(ack: ShuffleAck): Unit = {
      logger.debug(s"Received ACK for partition $partitionId: ${ack.getBytesReceived} bytes")
    }
    override def onError(t: Throwable): Unit = {
      logger.error(s"Shuffle error for partition $partitionId: ${t.getMessage}")
    }
    override def onCompleted(): Unit = {
      logger.info(s"Shuffle completed for partition $partitionId")
    }
  }

  val requestObserver = stub.shuffleData(responseObserver)

  // ì²­í¬ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡
  val input = new BufferedInputStream(new FileInputStream(partitionFile))
  val buffer = new Array[Byte](1024 * 1024)  // 1MB ì²­í¬

  var bytesRead = 0
  while ({bytesRead = input.read(buffer); bytesRead > 0}) {
    val chunk = ShuffleDataChunk.newBuilder()
      .setPartitionId(partitionId)
      .setData(ByteString.copyFrom(buffer, 0, bytesRead))
      .build()

    requestObserver.onNext(chunk)
  }

  input.close()
  requestObserver.onCompleted()

  channel.shutdown()
  channel.awaitTermination(60, TimeUnit.SECONDS)
}
```

### 4.4 Phase 4: Merge Algorithm â­ ìˆ˜ì •

#### 4.4.1 íŒŒí‹°ì…˜ë³„ K-way Merge

```scala
def mergeAllPartitions(
    receivedPartitions: Map[Int, List[File]],  // partitionID â†’ files
    outputDir: File): List[File] = {

  val outputFiles = mutable.ListBuffer[File]()

  // ê° íŒŒí‹°ì…˜ì„ ê°œë³„ì ìœ¼ë¡œ merge
  for ((partitionID, files) <- receivedPartitions.toList.sortBy(_._1)) {
    val outputFile = new File(outputDir, s"partition.$partitionID")
    kWayMergeAtomic(files, outputFile)
    outputFiles += outputFile

    logger.info(s"Created partition.$partitionID (${outputFile.length() / 1e6} MB)")
  }

  outputFiles.toList
}
```

#### 4.4.2 K-way Merge with Atomic Write

```scala
case class RecordWithSource(
  record: Array[Byte],
  sourceId: Int
)

def kWayMergeAtomic(
    inputFiles: List[File],
    outputFile: File): Unit = {

  // ì„ì‹œ íŒŒì¼ì— ë¨¼ì € ì“°ê¸°
  val tempFile = new File(outputFile.getParent, s".${outputFile.getName}.tmp")

  // Priority Queue (min-heap)
  implicit val ord: Ordering[RecordWithSource] = Ordering.by { rws =>
    rws.record.take(10)
  }(Ordering.by[Array[Byte], String](_.map("%02x".format(_)).mkString).reverse)

  val heap = mutable.PriorityQueue[RecordWithSource]()
  val readers = inputFiles.zipWithIndex.map { case (file, idx) =>
    new BufferedInputStream(new FileInputStream(file), 1024 * 1024)
  }

  // ì´ˆê¸°í™”: ê° íŒŒì¼ì—ì„œ ì²« ë ˆì½”ë“œ ì½ê¸°
  readers.zipWithIndex.foreach { case (reader, idx) =>
    val record = new Array[Byte](100)
    if (reader.read(record) == 100) {
      heap.enqueue(RecordWithSource(record.clone(), idx))
    }
  }

  val output = new BufferedOutputStream(
    new FileOutputStream(tempFile),
    4 * 1024 * 1024  // 4MB ë²„í¼
  )

  // Merge
  while (heap.nonEmpty) {
    val min = heap.dequeue()
    output.write(min.record)

    // ê°™ì€ ì†ŒìŠ¤ì—ì„œ ë‹¤ìŒ ë ˆì½”ë“œ ì½ê¸°
    val record = new Array[Byte](100)
    if (readers(min.sourceId).read(record) == 100) {
      heap.enqueue(RecordWithSource(record, min.sourceId))
    }
  }

  output.close()
  readers.foreach(_.close())

  // Atomic rename
  if (!tempFile.renameTo(outputFile)) {
    throw new IOException(s"Failed to create final partition file: $outputFile")
  }
}
```

---

## 5. ë„¤íŠ¸ì›Œí¬ í†µì‹  ì„¤ê³„

### 5.1 Protocol Buffers ì •ì˜ â­ ìˆ˜ì •

```protobuf
syntax = "proto3";

package distsort;

// ========== Master Service ==========

service MasterService {
  rpc RegisterWorker(WorkerInfo) returns (RegistrationResponse);
  rpc SendSample(SampleData) returns (Ack);
  rpc ReportCompletion(CompletionInfo) returns (Ack);
}

message WorkerInfo {
  string worker_id = 1;
  string host = 2;
  int32 port = 3;
  repeated string input_directories = 4;
  string output_directory = 5;
  int64 total_input_size = 6;
  // DataFormat format = 7;  // â­ DEPRECATED: ìë™ ê°ì§€ ì‚¬ìš©, í•„ë“œ ì‚¬ìš© ì•ˆ í•¨
}

// â­ DataFormat enumì€ ë‚´ë¶€ êµ¬í˜„ìš©ìœ¼ë¡œë§Œ ì‚¬ìš© (protobufì—ì„œëŠ” ì‚¬ìš© ì•ˆ í•¨)
// enum DataFormat {
//   BINARY = 0;
//   ASCII = 1;
// }

message RegistrationResponse {
  bool success = 1;
  string message = 2;
  int32 worker_index = 3;  // ì´ Workerì˜ ì¸ë±ìŠ¤ (íŒŒí‹°ì…˜ í• ë‹¹ì— ì‚¬ìš©)
}

message SampleData {
  string worker_id = 1;
  repeated bytes keys = 2;
  int32 sample_count = 3;
}

message CompletionInfo {
  string worker_id = 1;
  repeated int32 partition_ids = 2;  // ì´ Workerê°€ ìƒì„±í•œ íŒŒí‹°ì…˜ ID ë¦¬ìŠ¤íŠ¸
  repeated int64 partition_sizes = 3;
  double elapsed_time_seconds = 4;
}

message Ack {
  bool success = 1;
  string message = 2;
}

// ========== Worker Service ==========

service WorkerService {
  rpc SetPartitionBoundaries(PartitionConfig) returns (Ack);  // â­ ë³€ê²½
  rpc ShuffleData(stream ShuffleDataChunk) returns (ShuffleAck);
  rpc GetStatus(StatusRequest) returns (WorkerStatus);
  rpc Reset(ResetRequest) returns (Ack);
}

message PartitionConfig {  // â­ NEW
  repeated bytes boundaries = 1;  // N-1 or M-1 ê°œì˜ ê²½ê³„
  int32 num_partitions = 2;       // N or M
  map<int32, int32> shuffle_map = 3;  // partitionID â†’ workerID â­ NEW
  repeated WorkerInfo all_workers = 4;  // ëª¨ë“  Worker ì •ë³´
}

message ShuffleDataChunk {
  int32 partition_id = 1;
  bytes data = 2;
  int64 chunk_offset = 3;
  bool is_last = 4;
}

message ShuffleAck {
  bool success = 1;
  string message = 2;
  int64 bytes_received = 3;
}

message StatusRequest {
  string worker_id = 1;
}

message WorkerStatus {
  enum Phase {
    INITIALIZING = 0;
    SAMPLING = 1;
    SORTING = 2;
    SHUFFLING = 3;
    MERGING = 4;
    COMPLETED = 5;
    FAILED = 6;
  }

  Phase current_phase = 1;
  double progress_percentage = 2;
  string message = 3;
}

message ResetRequest {
  string reason = 1;
}
```

### 5.2 Master êµ¬í˜„ â­ ìˆ˜ì •

```scala
class MasterServer(numWorkers: Int, numPartitions: Int)
    extends MasterServiceGrpc.MasterServiceImplBase {

  private val workers = new ConcurrentHashMap[String, WorkerInfo]()
  private val samples = new ConcurrentHashMap[String, SampleData]()
  private val completions = new AtomicInteger(0)
  private val latch = new CountDownLatch(numWorkers)

  override def registerWorker(
      request: WorkerInfo,
      responseObserver: StreamObserver[RegistrationResponse]): Unit = {

    val workerId = request.getWorkerId
    workers.put(workerId, request)

    // Worker Index í• ë‹¹ (ë“±ë¡ ìˆœì„œ)
    val workerIndex = workers.size() - 1

    System.err.println(s"[INFO] Worker registered: $workerId at ${request.getHost}:${request.getPort} (index=$workerIndex)")

    val response = RegistrationResponse.newBuilder()
      .setSuccess(true)
      .setWorkerIndex(workerIndex)
      .setMessage(s"Registration successful. Your index is $workerIndex")
      .build()

    responseObserver.onNext(response)
    responseObserver.onCompleted()

    latch.countDown()
  }

  override def sendSample(
      request: SampleData,
      responseObserver: StreamObserver[Ack]): Unit = {

    samples.put(request.getWorkerId, request)
    System.err.println(s"[INFO] Received sample from ${request.getWorkerId}: ${request.getSampleCount} keys")

    if (samples.size() == numWorkers) {
      calculateAndBroadcastConfig()
    }

    responseObserver.onNext(Ack.newBuilder().setSuccess(true).build())
    responseObserver.onCompleted()
  }

  private def calculateAndBroadcastConfig(): Unit = {
    // 1. ìƒ˜í”Œ ì •ë ¬ ë° ê²½ê³„ ê³„ì‚°
    val allKeys = samples.values().asScala.flatMap(_.getKeysList.asScala).toArray
    val sortedKeys = allKeys.sortWith { (a, b) =>
      compareKeys(a.toByteArray, b.toByteArray) < 0
    }

    val boundaries = (1 until numPartitions).map { i =>
      val idx = (sortedKeys.length * i) / numPartitions
      sortedKeys(idx)
    }

    System.err.println(s"[INFO] Calculated ${boundaries.length} partition boundaries for $numPartitions partitions")

    // 2. shuffleMap ìƒì„± â­ NEW
    val shuffleMap = createShuffleMap(numWorkers, numPartitions)
    System.err.println(s"[INFO] shuffleMap: $shuffleMap")

    // 3. PartitionConfig ìƒì„± ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸
    val configMsg = PartitionConfig.newBuilder()
      .addAllBoundaries(boundaries.map(ByteString.copyFrom).asJava)
      .setNumPartitions(numPartitions)
      .putAllShuffleMap(shuffleMap.map { case (k, v) => (k: Integer, v: Integer) }.asJava)
      .addAllAllWorkers(workers.values().asScala.toList.asJava)
      .build()

    workers.values().asScala.foreach { workerInfo =>
      val channel = createGrpcChannelWithRetry(workerInfo.getHost, workerInfo.getPort)
      val stub = WorkerServiceGrpc.newBlockingStub(channel)
      stub.setPartitionBoundaries(configMsg)
      channel.shutdown()
    }
  }

  private def createShuffleMap(numWorkers: Int, numPartitions: Int): Map[Int, Int] = {
    val shuffleMap = mutable.Map[Int, Int]()
    val partitionsPerWorker = numPartitions / numWorkers

    for (partitionID <- 0 until numPartitions) {
      val workerID = partitionID / partitionsPerWorker
      val finalWorkerID = if (workerID >= numWorkers) numWorkers - 1 else workerID
      shuffleMap(partitionID) = finalWorkerID
    }

    shuffleMap.toMap
  }

  override def reportCompletion(
      request: CompletionInfo,
      responseObserver: StreamObserver[Ack]): Unit = {

    System.err.println(s"[INFO] Worker ${request.getWorkerId} completed in ${request.getElapsedTimeSeconds}s")
    System.err.println(s"[INFO] Created partitions: ${request.getPartitionIdsList.asScala.mkString(", ")}")

    if (completions.incrementAndGet() == numWorkers) {
      System.err.println("[INFO] All workers completed! Job finished.")
      printFinalOrdering()
    }

    responseObserver.onNext(Ack.newBuilder().setSuccess(true).build())
    responseObserver.onCompleted()
  }

  private def printFinalOrdering(): Unit = {
    // â­ PDF Algorithm Phase 0:
    // print "Master IP:Port"
    // for each worker in workerList do
    //     print worker.IP
    // end for

    val masterAddress = sys.env.getOrElse("MASTER_HOST",
      InetAddress.getLocalHost.getHostAddress
    )
    val masterPort = server.getPort  // ì‹¤ì œ bindëœ í¬íŠ¸

    val orderedWorkers = workers.values().asScala.toList
      .sortBy(_.getWorkerIndex)

    // stdoutìœ¼ë¡œë§Œ ì¶œë ¥ (ë¡œê·¸ì™€ ë¶„ë¦¬)
    // Line 1: Master IP:Port
    System.out.println(s"$masterAddress:$masterPort")

    // Line 2: Worker IPs (ì½¤ë§ˆë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ì—) â­ ìˆ˜ì •
    val workerIPs = orderedWorkers.map(_.getHost).mkString(", ")
    System.out.println(workerIPs)

    System.out.flush()
  }
}
```

---

## 6. ì¥ì•  í—ˆìš©ì„± ë©”ì»¤ë‹ˆì¦˜

### 6.1 ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤

```
ì‹œë‚˜ë¦¬ì˜¤ 1: Sort ì¤‘ Worker Crash
  Worker2 ì •ë ¬ ì¤‘ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
  â†’ ì„ì‹œ íŒŒì¼ ì¼ë¶€ë§Œ ìƒì„±ëœ ìƒíƒœ
  â†’ ì¬ì‹œì‘ ì‹œ ì„ì‹œ íŒŒì¼ ì‚­ì œ í›„ ì²˜ìŒë¶€í„°

ì‹œë‚˜ë¦¬ì˜¤ 2: Shuffle ì¤‘ Worker Crash
  Worker2ê°€ ë°ì´í„° ì†¡ì‹  ì¤‘ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
  â†’ ì¼ë¶€ WorkerëŠ” ë°ì´í„° ë°›ì•˜ì§€ë§Œ ë‚˜ë¨¸ì§€ëŠ” ëª» ë°›ìŒ
  â†’ ì¬ì‹œì‘ ì‹œ ëª¨ë“  Workerê°€ Shuffle ì¬ì‹œì‘

ì‹œë‚˜ë¦¬ì˜¤ 3: Merge ì¤‘ Worker Crash
  Worker2ê°€ ë³‘í•© ì¤‘ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
  â†’ ìµœì¢… ì¶œë ¥ íŒŒì¼ ë¯¸ì™„ì„±
  â†’ ì¬ì‹œì‘ ì‹œ ë³‘í•© ì¬ì‹œì‘
```

### 6.2 ë³µêµ¬ ì „ëµ

#### 6.2.1 ë©±ë“±ì„± ë³´ì¥

```scala
class WorkerNode {

  def start(): Unit = {
    try {
      // ì‹œì‘ ì „ ì •ë¦¬
      cleanupTemporaryFiles()
      cleanupOutputFiles()

      // ì •ìƒ ì‘ì—… ìˆ˜í–‰
      performSorting()

    } catch {
      case e: Exception =>
        logger.error("Worker failed", e)
        cleanupTemporaryFiles()
        cleanupOutputFiles()
        throw e
    }
  }

  private def cleanupTemporaryFiles(): Unit = {
    val tempDir = new File(config.tempDir, s"sort_work_$workerId")
    if (tempDir.exists()) {
      FileUtils.deleteRecursively(tempDir)
      logger.info("Cleaned up temporary files")
    }
  }

  private def cleanupOutputFiles(): Unit = {
    val outputDirFile = new File(config.outputDir)
    if (outputDirFile.exists()) {
      outputDirFile.listFiles().foreach { file =>
        if (file.getName.startsWith("partition.") ||
            file.getName.startsWith(".partition.")) {
          file.delete()
          logger.info(s"Deleted incomplete output: ${file.getName}")
        }
      }
    }
  }
}
```

---

## 7. ë©€í‹°ìŠ¤ë ˆë“œ ë° ë³‘ë ¬ ì²˜ë¦¬

### 7.1 Sort & Partition ë³‘ë ¬í™” â­ ìˆ˜ì •

```scala
class ParallelSorter(numThreads: Int = 4) {

  private val executor = Executors.newFixedThreadPool(numThreads)

  def sortAll(inputFiles: List[File]): List[File] = {
    // â­ format íŒŒë¼ë¯¸í„° ì œê±° - ê° íŒŒì¼ë§ˆë‹¤ ìë™ ê°ì§€
    val futures = inputFiles.map { file =>
      executor.submit(new Callable[File] {
        override def call(): File = sortChunk(file)  // ìë™ ê°ì§€ ì‚¬ìš©
      })
    }

    futures.map(_.get())
  }

  def partitionAll(sortedChunks: List[File],
                   boundaries: Array[Array[Byte]],
                   numPartitions: Int): Unit = {
    val futures = sortedChunks.map { chunk =>
      executor.submit(new Callable[Unit] {
        override def call(): Unit =
          partitionSortedChunk(chunk, boundaries, numPartitions, outputDir)
      })
    }

    futures.foreach(_.get())
  }

  def shutdown(): Unit = {
    executor.shutdown()
    executor.awaitTermination(1, TimeUnit.HOURS)
  }
}
```

---

## 8. êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 8.1 í”„ë¡œì íŠ¸ êµ¬ì¡°

```
project_2025/
â”œâ”€â”€ build.sbt
â”œâ”€â”€ project/
â”‚   â””â”€â”€ build.properties
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â”œâ”€â”€ scala/
â”‚       â”‚   â””â”€â”€ distsort/
â”‚       â”‚       â”œâ”€â”€ Main.scala
â”‚       â”‚       â”œâ”€â”€ master/
â”‚       â”‚       â”‚   â”œâ”€â”€ MasterServer.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ PartitionCalculator.scala
â”‚       â”‚       â”‚   â””â”€â”€ ShuffleMapBuilder.scala        â­ NEW
â”‚       â”‚       â”œâ”€â”€ worker/
â”‚       â”‚       â”‚   â”œâ”€â”€ WorkerNode.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ Sampler.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ Sorter.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ Partitioner.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ Shuffler.scala                 â­ ìˆ˜ì •
â”‚       â”‚       â”‚   â””â”€â”€ Merger.scala
â”‚       â”‚       â”œâ”€â”€ common/
â”‚       â”‚       â”‚   â”œâ”€â”€ RecordComparator.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ RecordReader.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ BinaryRecordReader.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ AsciiRecordReader.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ FileUtils.scala
â”‚       â”‚       â”‚   â”œâ”€â”€ NetworkUtils.scala
â”‚       â”‚       â”‚   â””â”€â”€ CommandLineParser.scala
â”‚       â”‚       â””â”€â”€ proto/
â”‚       â”‚           â””â”€â”€ (generated proto files)
â”‚       â”œâ”€â”€ protobuf/
â”‚       â”‚   â””â”€â”€ distsort.proto
â”‚       â””â”€â”€ resources/
â”‚           â””â”€â”€ logback.xml
â”œâ”€â”€ plan/
â”‚   â”œâ”€â”€ 2025-10-24_init_plan.md
â”‚   â”œâ”€â”€ 2025-10-24_init_plan_ver2.md
â”‚   â””â”€â”€ 2025-10-24_plan_ver3.md               â­ NEW
â””â”€â”€ README.md
```

### 8.2 Main í´ë˜ìŠ¤ â­ ìˆ˜ì •

```scala
object Main {
  def main(args: Array[String]): Unit = {
    if (args.isEmpty) {
      CommandLineParser.printUsage()
      System.exit(1)
    }

    args(0).toLowerCase match {
      case "master" =>
        val numWorkers = args(1).toInt
        val numPartitions = if (args.length > 2) args(2).toInt else numWorkers
        MasterMain.run(numWorkers, numPartitions)

      case "worker" =>
        val config = CommandLineParser.parseWorkerArgs(args.drop(1))
        WorkerMain.run(config)

      case _ =>
        println(s"Unknown command: ${args(0)}")
        CommandLineParser.printUsage()
        System.exit(1)
    }
  }
}
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```bash
# Master (Strategy A: 3 workers, 3 partitions)
$ sbt "runMain distsort.Main master 3"

# Master (Strategy B: 3 workers, 9 partitions)
$ sbt "runMain distsort.Main master 3 9"

# Worker
$ sbt "runMain distsort.Main worker 192.168.1.1:30000 -I /data1 -O /output"
```

---

## 9. ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 9.1 I/O ìµœì í™”

#### 9.1.1 ë²„í¼ë§

```scala
// ì˜¬ë°”ë¥¸ ì˜ˆ: ë²„í¼ë§ ì‚¬ìš©
val input = new BufferedInputStream(
  new FileInputStream(file),
  1024 * 1024  // 1MB ë²„í¼
)
val record = new Array[Byte](100)
while (input.read(record) == 100) {
  process(record)
}
```

### 9.2 ë””ìŠ¤í¬ ê³µê°„ ì‚¬ì „ í™•ì¸

```scala
def ensureSufficientDiskSpace(
    tempDir: File,
    outputDir: File,
    inputSize: Long): Unit = {

  val requiredTemp = inputSize * 2
  val requiredOutput = inputSize

  val tempAvailable = tempDir.getUsableSpace
  val outputAvailable = outputDir.getUsableSpace

  if (tempAvailable < requiredTemp * 1.5) {
    throw new IOException(
      f"Insufficient temp disk space: ${tempAvailable / 1e9}%.1f GB available, " +
      f"${requiredTemp * 1.5 / 1e9}%.1f GB required"
    )
  }

  if (outputAvailable < requiredOutput * 1.2) {
    throw new IOException(
      f"Insufficient output disk space: ${outputAvailable / 1e9}%.1f GB available, " +
      f"${requiredOutput * 1.2 / 1e9}%.1f GB required"
    )
  }
}
```

---

## 10. í…ŒìŠ¤íŠ¸ ì „ëµ

### 10.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```scala
class ShuffleMapTest extends AnyFlatSpec with Matchers {

  "createShuffleMap" should "correctly assign partitions in Strategy A" in {
    val shuffleMap = MasterServer.createShuffleMap(3, 3)
    shuffleMap shouldEqual Map(0 -> 0, 1 -> 1, 2 -> 2)
  }

  it should "correctly assign partitions in Strategy B" in {
    val shuffleMap = MasterServer.createShuffleMap(3, 9)
    shuffleMap shouldEqual Map(
      0 -> 0, 1 -> 1, 2 -> 2,
      3 -> 0, 4 -> 1, 5 -> 2,
      6 -> 0, 7 -> 1, 8 -> 2
    )
  }

  it should "handle edge case where numPartitions is not divisible by numWorkers" in {
    val shuffleMap = MasterServer.createShuffleMap(3, 10)
    shuffleMap(9) should be < 3  // ë§ˆì§€ë§‰ íŒŒí‹°ì…˜ë„ ìœ íš¨í•œ Workerì— í• ë‹¹
  }
}
```

---

## 11. ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤ ìƒì„¸

### 11.1 Master ëª…ë ¹í–‰ â­ ìˆ˜ì •

```bash
sbt "runMain distsort.Main master <N> [M]"
```

**ë§¤ê°œë³€ìˆ˜:**
- `<N>`: Worker ìˆ˜ (í•„ìˆ˜)
- `[M]`: íŒŒí‹°ì…˜ ìˆ˜ (ì„ íƒ, ê¸°ë³¸ê°’ = N)

**ì˜ˆì‹œ:**
```bash
# Strategy A (3 workers, 3 partitions)
$ sbt "runMain distsort.Main master 3"

# Strategy B (3 workers, 9 partitions)
$ sbt "runMain distsort.Main master 3 9"
```

**ì¶œë ¥:**
- **stdout**: ì •ë ¬ëœ Worker ì£¼ì†Œ (ì‰¼í‘œ êµ¬ë¶„)
- **stderr**: ë¡œê·¸ ë©”ì‹œì§€

### 11.2 Worker ëª…ë ¹í–‰

```bash
sbt "runMain distsort.Main worker <master> -I <dir1> <dir2> ... -O <output> [options]"
```

**í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜:**
- `<master>`: Master ì£¼ì†Œ (host:port)
- `-I <dirs...>`: ì…ë ¥ ë””ë ‰í† ë¦¬ë“¤
- `-O <output>`: ì¶œë ¥ ë””ë ‰í† ë¦¬

**ì„ íƒì  ë§¤ê°œë³€ìˆ˜:**
- `--temp <dir>`: ì¤‘ê°„ íŒŒì¼ ì €ì¥ ìœ„ì¹˜
- `--threads <N>`: ìŠ¤ë ˆë“œ ìˆ˜

**ì°¸ê³ :**
- ASCII/Binary í˜•ì‹ì€ ìë™ìœ¼ë¡œ ê°ì§€ë¨ (ëª…ë ¹í–‰ ì˜µì…˜ ë¶ˆí•„ìš”)
- ê° íŒŒì¼ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ í˜•ì‹ ê°ì§€ (í˜¼í•© ì…ë ¥ ì§€ì›)

---

## 12. ì…ë ¥ í˜•ì‹ ì²˜ë¦¬

### 12.1 ìë™ í˜•ì‹ ê°ì§€ â­ NEW

**PDF ìš”êµ¬ì‚¬í•­:**
> "Should work on both ASCII and binary input **without requiring an option**"

```scala
object InputFormatDetector {
  /**
   * íŒŒì¼ì˜ ì²« 1000 ë°”ì´íŠ¸ë¥¼ ì½ì–´ì„œ ASCII vs Binary íŒë³„
   */
  def detectFormat(file: File): DataFormat = {
    val buffer = new Array[Byte](1000)
    val inputStream = new FileInputStream(file)

    try {
      val bytesRead = inputStream.read(buffer)

      if (bytesRead <= 0) {
        logger.warn(s"Empty file: ${file.getName}, defaulting to Binary")
        return DataFormat.Binary
      }

      // ASCII printable: 0x20-0x7E (space ~ ~), plus \n (0x0A), \r (0x0D)
      val asciiLikeCount = buffer.take(bytesRead).count { b =>
        (b >= 32 && b <= 126) || b == '\n' || b == '\r'
      }

      val asciiRatio = asciiLikeCount.toDouble / bytesRead

      logger.debug(s"File: ${file.getName}, ASCII ratio: $asciiRatio")

      if (asciiRatio > 0.9) {
        logger.info(s"Detected ASCII format for file: ${file.getName}")
        DataFormat.Ascii
      } else {
        logger.info(s"Detected Binary format for file: ${file.getName}")
        DataFormat.Binary
      }
    } finally {
      inputStream.close()
    }
  }
}
```

### 12.2 ë ˆì½”ë“œ ë¦¬ë” ì¶”ìƒí™”

```scala
sealed trait DataFormat
object DataFormat {
  case object Binary extends DataFormat
  case object Ascii extends DataFormat
}

trait RecordReader {
  def readRecord(input: InputStream): Option[Array[Byte]]
}

object RecordReader {
  def create(format: DataFormat): RecordReader = format match {
    case DataFormat.Binary => new BinaryRecordReader()
    case DataFormat.Ascii => new AsciiRecordReader()
  }
}
```

### 12.3 Binary í˜•ì‹ ë¦¬ë”

```scala
class BinaryRecordReader extends RecordReader {
  override def readRecord(input: InputStream): Option[Array[Byte]] = {
    val record = new Array[Byte](100)
    val bytesRead = input.read(record)

    if (bytesRead == 100) Some(record)
    else if (bytesRead == -1) None
    else throw new IOException(s"Incomplete record: $bytesRead bytes")
  }
}
```

### 12.4 ASCII í˜•ì‹ ë¦¬ë”

```scala
class AsciiRecordReader extends RecordReader {
  override def readRecord(input: InputStream): Option[Array[Byte]] = {
    val line = new Array[Byte](102)  // key(10) + space(1) + value(90) + newline(1)
    val bytesRead = input.read(line)

    if (bytesRead == -1) return None
    if (bytesRead != 102) throw new IOException(s"Invalid ASCII record: $bytesRead bytes")
    if (line(10) != ' '.toByte) throw new IOException("Expected space at position 10")
    if (line(101) != '\n'.toByte) throw new IOException("Expected newline at position 101")

    val record = new Array[Byte](100)
    System.arraycopy(line, 0, record, 0, 10)    // key
    System.arraycopy(line, 11, record, 10, 90)  // value

    Some(record)
  }
}
```

---

## 13. ê°œë°œ ë§ˆì¼ìŠ¤í†¤ â­ ëŒ€í­ ìˆ˜ì •

### Milestone 1: ê¸°ë³¸ ì¸í”„ë¼ (Week 1-2)
- [ ] í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
- [ ] Protocol Buffers ì •ì˜ (shuffleMap í¬í•¨)
- [ ] RecordReader ì¶”ìƒí™” ë° êµ¬í˜„
- [ ] CommandLineParser êµ¬í˜„
- [ ] Master/Worker ìŠ¤ì¼ˆë ˆí†¤ ì½”ë“œ
- [ ] gRPC í†µì‹  ê¸°ë³¸ êµ¬í˜„
- [ ] ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (1 Master + 1 Worker)

**ê²€ì¦:**
```bash
$ sbt "runMain distsort.Main master 1"
$ sbt "runMain distsort.Main worker 127.0.0.1:30000 -I test_input -O test_output"
> Worker registered successfully with index 0
```

### Milestone 2: Strategy A êµ¬í˜„ (Week 3-4)
- [ ] ë™ì  ìƒ˜í”Œë§ ë¹„ìœ¨ ê³„ì‚°
- [ ] ìƒ˜í”Œë§ êµ¬í˜„ (ASCII/Binary)
- [ ] shuffleMap ìƒì„± ë¡œì§ (Nâ†’N)
- [ ] ì •ë ¬ ë° íŒŒí‹°ì…”ë‹ (Nê°œ íŒŒí‹°ì…˜)
- [ ] Shuffle êµ¬í˜„ (ì¬ì‹œë„ ë¡œì§)
- [ ] Merge êµ¬í˜„ (1ê°œ íŒŒí‹°ì…˜/Worker)
- [ ] ë¡œì»¬ í†µí•© í…ŒìŠ¤íŠ¸

**ê²€ì¦:**
```bash
# Strategy A: 3 workers, 3 partitions
$ sbt "runMain distsort.Main master 3"
$ # ê° Worker ì‹¤í–‰...
$ # ì¶œë ¥ í™•ì¸
$ ls worker0/output/  # partition.0
$ ls worker1/output/  # partition.1
$ ls worker2/output/  # partition.2
```

### Milestone 3: ì¥ì•  í—ˆìš©ì„± (Week 5)
- [ ] ì¬ì‹œì‘ ë¡œì§ êµ¬í˜„
- [ ] ì„ì‹œ íŒŒì¼ ì •ë¦¬
- [ ] Worker ì¥ì•  í…ŒìŠ¤íŠ¸
- [ ] Atomic write ê²€ì¦
- [ ] ë„¤íŠ¸ì›Œí¬ ì¬ì‹œë„ í…ŒìŠ¤íŠ¸

**ê²€ì¦:**
```bash
$ ./test_failure.sh
> Worker 2 killed at t=10s
> Worker 2 restarted at t=12s
> All workers completed successfully
```

### Milestone 4: Strategy B êµ¬í˜„ (Week 6) âœ… PDF í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- [ ] shuffleMap ë¡œì§ í™•ì¥ (Nâ†’M)
- [ ] íŒŒí‹°ì…˜ ìˆ˜ ì¦ê°€ ì§€ì› (M > N)
- [ ] Workerë‹¹ ì—¬ëŸ¬ íŒŒí‹°ì…˜ merge
- [ ] íŒŒí‹°ì…˜ ë²ˆí˜¸ ë¶ˆì—°ì† ì²˜ë¦¬
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ (3 workers, 9 partitions)

**ì¤‘ìš”:** PDF ìš”êµ¬ì‚¬í•­ì— ë”°ë¥´ë©´ ê° WorkerëŠ” ì—¬ëŸ¬ partition íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ìˆì–´ì•¼ í•¨

**ê²€ì¦:**
```bash
# Strategy B: 3 workers, 9 partitions
$ sbt "runMain distsort.Main master 3 9"
$ # ê° Worker ì‹¤í–‰...
$ # ì¶œë ¥ í™•ì¸
$ ls worker0/output/  # partition.0, partition.1, partition.2
$ ls worker1/output/  # partition.3, partition.4, partition.5
$ ls worker2/output/  # partition.6, partition.7, partition.8
```

### Milestone 5: ì„±ëŠ¥ ìµœì í™” (Week 7)
- [ ] ë©€í‹°ìŠ¤ë ˆë“œ êµ¬í˜„
- [ ] I/O ë²„í¼ë§ ìµœì í™”
- [ ] ë„¤íŠ¸ì›Œí¬ ë°°ì¹˜ ì „ì†¡
- [ ] ë””ìŠ¤í¬ ê³µê°„ ì‚¬ì „ í™•ì¸
- [ ] í”„ë¡œíŒŒì¼ë§ ë° ë³‘ëª© ì œê±°
- [ ] ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ (50GB+)

**ê²€ì¦:**
```bash
$ ./benchmark.sh
> 50GB sorted in 180 seconds
> Throughput: 285 MB/s
```

### Milestone 6: ë§ˆë¬´ë¦¬ (Week 8)
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (Strategy B ì¤‘ì‹¬)
- [ ] Master ì¶œë ¥ í˜•ì‹ ê²€ì¦ (N+1 ì¤„, Worker IPë§Œ)
- [ ] PDF ìš”êµ¬ì‚¬í•­ ìµœì¢… í™•ì¸
- [ ] ë¬¸ì„œí™” ì™„ì„±
- [ ] ì½”ë“œ ë¦¬íŒ©í† ë§
- [ ] ìµœì¢… ë°ëª¨ ì¤€ë¹„

---

## 14. ì°¸ê³  ìë£Œ

### 14.1 í•µì‹¬ ì•Œê³ ë¦¬ì¦˜
- External Sorting: Knuth, TAOCP Vol. 3
- K-way Merge: Priority Queue ê¸°ë°˜ ë³‘í•©
- Sampling for Partitioning: TeraSort ë…¼ë¬¸

### 14.2 ì‹œìŠ¤í…œ ì„¤ê³„
- MapReduce: Dean & Ghemawat, OSDI 2004
- Spark: Zaharia et al., NSDI 2012
- Distributed Sorting: Sort Benchmark ìš°ìŠ¹ ë…¼ë¬¸ë“¤

### 14.3 êµ¬í˜„ ì°¸ê³ 
- gRPC ê³µì‹ ë¬¸ì„œ: https://grpc.io/docs/languages/java/
- Protocol Buffers: https://protobuf.dev/
- **gensort/valsort ê³µì‹ ì‚¬ì´íŠ¸:** http://www.ordinal.com/gensort.html

#### gensort/valsort ë„êµ¬ ì‚¬ìš©ë²•

**gensort**: ì •ë ¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì…ë ¥ ë°ì´í„° ìƒì„± ë„êµ¬
**valsort**: ì •ë ¬ ê²°ê³¼ì˜ ì •í™•ì„± ê²€ì¦ ë„êµ¬

**ë ˆì½”ë“œ í˜•ì‹:**
- ê° ë ˆì½”ë“œ: **100 bytes** (ê³ ì • ê¸¸ì´)
  - **ì²˜ìŒ 10 bytes**: Key (ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë¶€ë¶„)
  - **ë‚˜ë¨¸ì§€ 90 bytes**: Value (ì •ë ¬ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, ë‹¨ìˆœíˆ ë”°ë¼ë‹¤ë‹ˆëŠ” ë°ì´í„°)
- **ì¤‘ìš”**: ì •ë ¬ ì‹œ ì²˜ìŒ 10 bytesë§Œ ë¹„êµí•˜ë©´ ë¨

**gensort ì‚¬ìš© ì˜ˆì‹œ:**
```bash
# Binary ëª¨ë“œ (ê¸°ë³¸)
# 1GB ë°ì´í„° ìƒì„± (10,000,000 ë ˆì½”ë“œ = 1,000,000,000 bytes)
gensort -b0 10000000 input.dat

# ASCII ëª¨ë“œ (ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” í˜•ì‹)
gensort -a 10000000 input_ascii.dat

# ì—¬ëŸ¬ íŒŒì¼ë¡œ ë¶„í•  ìƒì„±
gensort -b0 5000000 input1.dat
gensort -b5000000 5000000 input2.dat
```

**valsort ì‚¬ìš© ì˜ˆì‹œ:**
```bash
# ì •ë ¬ ê²°ê³¼ ê²€ì¦ (Binary ëª¨ë“œ)
valsort output.dat
# ì¶œë ¥: "SUCCESS" ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€

# ASCII ëª¨ë“œ ê²€ì¦
valsort -a output_ascii.dat

# ì—¬ëŸ¬ íŒŒì¼ ê²€ì¦ (íŒŒì¼ë“¤ì´ ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ì–´ ìˆëŠ”ì§€)
valsort -o output_summary.txt partition.*
```

**í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©:**
```bash
# 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (ì˜ˆ: 100MB = 1,000,000 ë ˆì½”ë“œ)
gensort -b0 1000000 /data1/input/test.dat

# 2. ë¶„ì‚° ì •ë ¬ ì‹¤í–‰
# Master: master 3
# Worker: worker 141.223.91.80:30040 -I /data1/input -O /home/gla/data

# 3. ê²°ê³¼ ê²€ì¦
valsort /home/gla/data/partition.*
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:**
1. **ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸**: 1MB (10,000 ë ˆì½”ë“œ) - ê¸°ëŠ¥ ê²€ì¦
2. **ì¤‘ê·œëª¨ í…ŒìŠ¤íŠ¸**: 100MB (1,000,000 ë ˆì½”ë“œ) - ì„±ëŠ¥ ì´ˆê¸° ì¸¡ì •
3. **ëŒ€ê·œëª¨ í…ŒìŠ¤íŠ¸**: 10GB (100,000,000 ë ˆì½”ë“œ) - ìµœì¢… ì„±ëŠ¥ í‰ê°€

### 14.4 Critical Implementation Requirements âš ï¸

#### Requirement 1: ASCII/Binary ìë™ ê°ì§€
```
âœ… ì˜µì…˜ ì—†ì´ ìë™ìœ¼ë¡œ ì…ë ¥ í¬ë§· ê°ì§€
âœ… InputFormatDetector ì‚¬ìš© (ASCII ratio > 0.9)
```

#### Requirement 2: ì…ë ¥ ë””ë ‰í† ë¦¬ ë³´í˜¸ âš ï¸ ë§¤ìš° ì¤‘ìš”
```
âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ì‚­ì œ ê¸ˆì§€
âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ì— ìƒˆ íŒŒì¼ ìƒì„± ê¸ˆì§€
âœ… ëª¨ë“  ì„ì‹œ íŒŒì¼ì€ tempBaseDirì—ë§Œ ìƒì„±
```

**ê²€ì¦**:
```bash
# ì‹¤í–‰ ì „í›„ ì…ë ¥ ë””ë ‰í† ë¦¬ ë¹„êµ
before=$(ls -la /data1/input)
./worker ...
after=$(ls -la /data1/input)
diff <(echo "$before") <(echo "$after")  # ì°¨ì´ ì—†ì–´ì•¼ í•¨
```

#### Requirement 3: ì„ì‹œ íŒŒì¼ ì •ë¦¬
```
âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ì—ëŠ” partition.* íŒŒì¼ë§Œ ì¡´ì¬
âœ… .tmp, .sorting/, chunk_* ë“± ëª¨ë‘ ì‚­ì œ
```

**ê²€ì¦**:
```bash
ls /home/gla/data
# ì˜ˆìƒ: partition.28 partition.29 partition.30 ...
# ê¸ˆì§€: partition.0.tmp, .sorting/, chunk_0000.sorted
```

#### Requirement 4: í¬íŠ¸ ë™ì  í• ë‹¹
```
âŒ í¬íŠ¸ í•˜ë“œì½”ë”© ê¸ˆì§€ (ì˜ˆ: port = 50051)
âœ… ServerBuilder.forPort(0) ì‚¬ìš©
âœ… ì‹¤ì œ í¬íŠ¸ = server.getPort
```

**ì´ìœ **: ê°™ì€ ë¨¸ì‹ ì—ì„œ ì—¬ëŸ¬ Worker ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥

#### Requirement 5: 32MB ê°€ì • ê¸ˆì§€ âš ï¸
```
âŒ ì…ë ¥ íŒŒì¼ì´ 32MBë¼ê³  ê°€ì •í•˜ì§€ ë§ ê²ƒ
âœ… 1KB ~ 10GB ì–´ë–¤ í¬ê¸°ë„ ì²˜ë¦¬ ê°€ëŠ¥
âœ… ì²­í¬ í¬ê¸°ëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ ë™ì  ê²°ì •
```

**ì˜ëª»ëœ ì½”ë“œ**:
```scala
// âŒ WRONG
val chunkSize = 32 * 1024 * 1024
val buffer = new Array[Byte](32 * 1024 * 1024)
```

**ì˜¬ë°”ë¥¸ ì½”ë“œ**:
```scala
// âœ… CORRECT
val availableMemory = Runtime.getRuntime.maxMemory()
val chunkSize = math.min(availableMemory / 10, 100 * 1024 * 1024)
```

#### Requirement 6: Worker í¬ë˜ì‹œ í…ŒìŠ¤íŠ¸ ëŒ€ë¹„
```
âš ï¸ í…ŒìŠ¤íŠ¸ ì¤‘ Workerê°€ ê°•ì œ ì¢…ë£Œë¨ (kill -9)
âœ… Worker Re-registrationìœ¼ë¡œ ë³µêµ¬
âœ… Idempotent operations
âœ… Atomic file operations (temp + rename)
```

**ìì„¸í•œ ë‚´ìš©**: `docs/0-implementation-decisions.md` Section 8 ì°¸ì¡°

---

## 15. ì˜ˆìƒ ì´ìŠˆ ë° í•´ê²°ì±…

### Issue 1: íŒŒí‹°ì…˜ ë¶ˆê· í˜•
**ì¦ìƒ:** ì¼ë¶€ Workerê°€ ë§¤ìš° í° íŒŒí‹°ì…˜ì„ ë°›ì•„ ë³‘ëª© ë°œìƒ

**í•´ê²°:**
- Strategy Bë¡œ ì „í™˜ (íŒŒí‹°ì…˜ ìˆ˜ ì¦ê°€)
- ë™ì  ìƒ˜í”Œë§ ë¹„ìœ¨ ì¡°ì •
- ìƒ˜í”Œ í¬ê¸° ì¦ê°€

### Issue 2: shuffleMap ì´í•´ ì˜¤ë¥˜
**ì¦ìƒ:** íŒŒí‹°ì…˜ì´ ì˜ëª»ëœ Workerë¡œ ì „ì†¡ë¨

**í•´ê²°:**
- shuffleMap ë¡œì§ ê²€ì¦ (ë‹¨ìœ„ í…ŒìŠ¤íŠ¸)
- ë¡œê·¸ ì¶”ê°€ (ì–´ëŠ íŒŒí‹°ì…˜ì´ ì–´ëŠ Workerë¡œ ê°€ëŠ”ì§€)
- Masterì™€ Workerê°€ ë™ì¼í•œ shuffleMap ì‚¬ìš© í™•ì¸

### Issue 3: íŒŒí‹°ì…˜ íŒŒì¼ ëˆ„ë½
**ì¦ìƒ:** Workerê°€ ë‹´ë‹¹í•œ ì¼ë¶€ íŒŒí‹°ì…˜ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•ŠìŒ

**í•´ê²°:**
- receivedPartitions Map í™•ì¸
- ëª¨ë“  íŒŒí‹°ì…˜ IDë¥¼ ìˆœíšŒí•˜ì—¬ merge
- ë¹ˆ íŒŒí‹°ì…˜ë„ íŒŒì¼ ìƒì„± (í¬ê¸° 0)

### Issue 4: ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ë¶€ì¡±
**ì¦ìƒ:** Shuffle ë‹¨ê³„ì—ì„œ ë§¤ìš° ëŠë¦¼

**í•´ê²°:**
- ì••ì¶• ì‚¬ìš©
- ë°°ì¹˜ í¬ê¸° ì¦ê°€
- ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
- Keep-alive ì„¤ì •

### Issue 5: ë©”ëª¨ë¦¬ ë¶€ì¡±
**ì¦ìƒ:** OutOfMemoryError

**í•´ê²°:**
- ì²­í¬ í¬ê¸° ê°ì†Œ
- ìŠ¤ë ˆë“œ ìˆ˜ ê°ì†Œ
- ë²„í¼ í¬ê¸° ì¡°ì •
- JVM í™ í¬ê¸° ì¦ê°€

### Issue 6: ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
**ì¦ìƒ:** ì‘ì—… ì¤‘ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

**í•´ê²°:**
- ì‹œì‘ ì „ ë””ìŠ¤í¬ ê³µê°„ ê²€ì¦
- ì„ì‹œ íŒŒì¼ ì¡°ê¸° ì •ë¦¬
- ì—¬ìœ  ê³µê°„ 50% í™•ë³´

---

## 16. ê²°ë¡ 

### 16.1 Version 3 ì£¼ìš” ì„±ê³¼

ì´ ì„¤ê³„ ë¬¸ì„œ v3ëŠ” **íŒŒí‹°ì…˜ ì „ëµì„ ëª…í™•íˆ êµ¬ë¶„**í•˜ê³  **shuffleMap ë¡œì§ì„ ì™„ì „íˆ êµ¬í˜„**í•œ ê²°ì •íŒì…ë‹ˆë‹¤.

**í•µì‹¬ ê°œì„ ì‚¬í•­:**

1. âœ… **Strategy A (Simple) vs B (Advanced) ëª…í™•í•œ êµ¬ë¶„**
   - Nâ†’N: ê° Worker 1ê°œ íŒŒí‹°ì…˜
   - Nâ†’M: ê° Worker ì—¬ëŸ¬ íŒŒí‹°ì…˜

2. âœ… **shuffleMap ìƒì„± ë° ì‚¬ìš© ë¡œì§ ì™„ì „ êµ¬í˜„**
   - Master: createShuffleMap()
   - Worker: shufflePartitions()
   - Protocol: shuffle_map í•„ë“œ ì¶”ê°€

3. âœ… **ë‘ ê°€ì§€ ë‹¤ì´ì–´ê·¸ë¨ ì œê³µ**
   - Strategy A: ë‹¨ìˆœ 1:1 ë§¤í•‘
   - Strategy B: ë³µì¡í•œ N:M ë§¤í•‘

4. âœ… **íŒŒí‹°ì…˜ í• ë‹¹ ê³µì‹ ëª…ì‹œ**
   - workerID = partitionID / partitionsPerWorker
   - ëª…í™•í•œ ìˆ˜ì‹ê³¼ ì˜ˆì‹œ

5. âœ… **Master ì¶œë ¥ ì˜ë¯¸ ìƒì„¸ ì„¤ëª…**
   - Worker ìˆœì„œ = íŒŒí‹°ì…˜ ë²ˆí˜¸ ìˆœì„œ
   - ì½ê¸° ìˆœì„œ ëª…ì‹œ

### 16.2 êµ¬í˜„ ë¡œë“œë§µ

**ë‹¨ê³„ë³„ ì ‘ê·¼:**

1. **Week 1-2: Milestone 1**
   - ê¸°ë³¸ ì¸í”„ë¼ êµ¬ì¶•
   - gRPC í†µì‹  ê²€ì¦

2. **Week 3-4: Milestone 2**
   - Strategy A (Simple) ì™„ì „ êµ¬í˜„
   - 3 workers, 3 partitions í…ŒìŠ¤íŠ¸

3. **Week 5: Milestone 3**
   - ì¥ì•  í—ˆìš©ì„± ì¶”ê°€
   - Crash & Restart ê²€ì¦

4. **Week 6: Milestone 4**
   - Strategy B (Advanced) í™•ì¥
   - 3 workers, 9 partitions í…ŒìŠ¤íŠ¸

5. **Week 7: Milestone 5**
   - ì„±ëŠ¥ ìµœì í™”
   - ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸

6. **Week 8: Milestone 6**
   - ìµœì¢… ê²€ì¦ ë° ë¬¸ì„œí™”

### 16.3 ì„±ê³µ ê¸°ì¤€

- âœ… ì •í™•ì„±: valsort í†µê³¼ (ASCII/Binary ëª¨ë‘)
- âœ… ì¥ì•  í—ˆìš©: Worker ì¬ì‹œì‘ í›„ ì •ìƒ ì™„ë£Œ
- âœ… í™•ì¥ì„±: Strategy A â†’ B ì „í™˜ ê°€ëŠ¥
- âœ… ì„±ëŠ¥: ë‹¨ì¼ ë¨¸ì‹  ëŒ€ë¹„ ìœ ì˜ë¯¸í•œ ì†ë„ í–¥ìƒ
- âœ… ì½”ë“œ í’ˆì§ˆ: ê¹”ë”í•˜ê³  ìœ ì§€ë³´ìˆ˜ ê°€ëŠ¥
- âœ… ëª…ì„¸ ì¤€ìˆ˜: PDF ìš”êµ¬ì‚¬í•­ 100% ì¶©ì¡±

---


**ë¬¸ì„œ ë²„ì „:** 3.0
**ìµœì¢… ìˆ˜ì •:** 2025-10-24
**ì‘ì„±ì:** Project Team
**ë³€ê²½ ì´ë ¥:**
- v1.0 (2025-10-24): ì´ˆê¸° ì„¤ê³„
- v2.0 (2025-10-24): PDF ëª…ì„¸ì„œ ìš”êµ¬ì‚¬í•­ ë°˜ì˜
- v3.0 (2025-10-24): íŒŒí‹°ì…˜ ì „ëµ ëª…í™•í™”, shuffleMap ë¡œì§ ì¶”ê°€
